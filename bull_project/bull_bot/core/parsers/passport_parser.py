import cv2
import pytesseract
import numpy as np
from pdf2image import convert_from_path
from PIL import Image
import os
import re
from dataclasses import dataclass
from datetime import datetime

@dataclass
class PassportData:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ø–∞—Å–ø–æ—Ä—Ç–∞"""
    last_name: str = ""
    first_name: str = ""
    gender: str = ""
    dob: str = ""
    iin: str = ""
    document_number: str = ""
    expiration_date: str = ""
    phone: str = ""  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–∞

    @property
    def full_name(self) -> str:
        return f"{self.last_name} {self.first_name}".strip()

    @property
    def is_valid(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö"""
        has_name = bool(self.last_name or self.first_name)
        has_iin = len(self.iin) == 12 if self.iin else False
        has_doc = bool(self.document_number)
        # –°—á–∏—Ç–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–º –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –∏–º—è –ò (–ò–ò–ù –ò–õ–ò –¥–æ–∫—É–º–µ–Ω—Ç)
        return has_name and (has_iin or has_doc)

    def to_dict(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è API"""
        return {
            "last_name": self.last_name or "-",
            "first_name": self.first_name or "-",
            "gender": self.gender or "M",
            "date_of_birth": self.dob or "-",
            "passport_num": self.document_number or "-",
            "phone": self.phone or "-",
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            "Last Name": self.last_name or "-",
            "First Name": self.first_name or "-",
            "Gender": self.gender or "M",
            "Date of Birth": self.dob or "-",
            "Document Number": self.document_number or "-",
            "Document Expiration": self.expiration_date or "-",
            "IIN": self.iin or "-",
            "MRZ_LAST": getattr(self, "mrz_last_name", None),
            "MRZ_FIRST": getattr(self, "mrz_first_name", None),
        }

class PassportParser:
    def __init__(self, poppler_path: str = None, debug: bool = False):
        self.poppler_path = poppler_path
        self.debug = debug
        self._date_cleaner = re.compile(r"\s+")
        self._cyr_map = {
            "–ê": "A", "–ë": "B", "–í": "V", "–ì": "G", "–î": "D", "–ï": "E", "–Å": "E",
            "–ñ": "ZH", "–ó": "Z", "–ò": "I", "–ô": "Y", "–ö": "K", "–õ": "L", "–ú": "M",
            "–ù": "N", "–û": "O", "–ü": "P", "–†": "R", "–°": "S", "–¢": "T", "–£": "U",
            "–§": "F", "–•": "KH", "–¶": "TS", "–ß": "CH", "–®": "SH", "–©": "SCH",
            "–™": "", "–´": "Y", "–¨": "", "–≠": "E", "–Æ": "YU", "–Ø": "YA",
            "“ö": "K", "”ò": "A", "“¢": "N", "“í": "G", "“Æ": "U", "“∞": "U", "”®": "O", "“∫": "H",
            "–∞": "A", "–±": "B", "–≤": "V", "–≥": "G", "–¥": "D", "–µ": "E", "—ë": "E",
            "–∂": "ZH", "–∑": "Z", "–∏": "I", "–π": "Y", "–∫": "K", "–ª": "L", "–º": "M",
            "–Ω": "N", "–æ": "O", "–ø": "P", "—Ä": "R", "—Å": "S", "—Ç": "T", "—É": "U",
            "—Ñ": "F", "—Ö": "KH", "—Ü": "TS", "—á": "CH", "—à": "SH", "—â": "SCH",
            "—ä": "", "—ã": "Y", "—å": "", "—ç": "E", "—é": "YU", "—è": "YA",
            "“õ": "K", "”ô": "A", "“£": "N", "“ì": "G", "“Ø": "U", "“±": "U", "”©": "O", "“ª": "H",
        }

    def _clean_date(self, value: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏."""
        if not value:
            return ""
        stripped = self._date_cleaner.sub("", value)
        stripped = stripped.replace('/', '.').replace('-', '.')
        if len(stripped) == 8 and stripped.isdigit():
            return f"{stripped[0:2]}.{stripped[2:4]}.{stripped[4:]}"
        return stripped

    def _contains_cyrillic(self, value: str) -> bool:
        return any("–ê" <= c <= "—è" or c in "–Å—ë“ö“õ”ò”ô“¢“£“í“ì“Æ“Ø“∞“±”®”©“∫“ª" for c in value or "")

    def _transliterate(self, value: str) -> str:
        if not value:
            return ""
        return "".join(self._cyr_map.get(ch, ch) for ch in value)

    def preprocess_image(self, image: Image.Image) -> np.ndarray:
        """–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        img = np.array(image)
        if len(img.shape) == 3:
            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # CLAHE –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

        return binary

    def extract_ocr_text(self, file_path: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Tesseract"""
        try:
            if file_path.lower().endswith('.pdf'):
                pages = convert_from_path(file_path, dpi=300, poppler_path=self.poppler_path)
                if not pages:
                    return ""
                pil_image = pages[0]
            else:
                pil_image = Image.open(file_path)

            processed_img = self.preprocess_image(pil_image)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —è–∑—ã–∫–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            text = pytesseract.image_to_string(
                processed_img,
                lang="kaz+rus+eng",
                config='--psm 6'  # Assume uniform block of text
            )

            if self.debug:
                print("üìÑ OCR TEXT START" + "="*40)
                print(text)
                print("="*40 + " OCR TEXT END")

            return text
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ OCR: {e}")
            return ""

    def get_gender_from_iin(self, iin: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∞ –ø–æ 7-–π —Ü–∏—Ñ—Ä–µ –ò–ò–ù"""
        if not iin or len(iin) != 12 or not iin.isdigit():
            return ""
        digit = int(iin[6])
        return "M" if digit in [1, 3, 5] else "F" if digit in [2, 4, 6] else ""

    def extract_date_from_iin(self, iin: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç—ã —Ä–æ–∂–¥–µ–Ω–∏—è –∏–∑ –ò–ò–ù (–ø–µ—Ä–≤—ã–µ 6 —Ü–∏—Ñ—Ä - YYMMDD)"""
        if not iin or len(iin) < 6 or not iin[:6].isdigit():
            return ""

        try:
            yy = int(iin[0:2])
            mm = int(iin[2:4])
            dd = int(iin[4:6])

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–µ–∫ –ø–æ 7-–π —Ü–∏—Ñ—Ä–µ
            century_digit = int(iin[6]) if len(iin) > 6 else 0
            if century_digit in [1, 2]:
                year = 1800 + yy
            elif century_digit in [3, 4]:
                year = 1900 + yy
            elif century_digit in [5, 6]:
                year = 2000 + yy
            else:
                year = 1900 + yy  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 1900-–µ

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –¥–∞—Ç—ã
            datetime(year, mm, dd)

            return f"{dd:02d}.{mm:02d}.{year}"
        except (ValueError, IndexError):
            return ""

    def _levenshtein_distance(self, s1: str, s2: str) -> int:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞ –º–µ–∂–¥—É –¥–≤—É–º—è —Å—Ç—Ä–æ–∫–∞–º–∏"""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)

        if len(s2) == 0:
            return len(s1)

        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row

        return previous_row[-1]

    def _are_similar_words(self, word1: str, word2: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ—Ö–æ–∂–∏ –ª–∏ –¥–≤–∞ —Å–ª–æ–≤–∞ (–≤–æ–∑–º–æ–∂–Ω–æ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç - –æ—à–∏–±–∫–∞ OCR)"""
        if not word1 or not word2:
            return False

        w1, w2 = word1.upper(), word2.upper()
        if w1 == w2:
            return True

        # –°–ª–æ–≤–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–Ω–æ–π –¥–ª–∏–Ω—ã
        if abs(len(w1) - len(w2)) > 3:
            return False

        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞
        distance = self._levenshtein_distance(w1, w2)
        max_len = max(len(w1), len(w2))

        # –ï—Å–ª–∏ —Å–ª–æ–≤–∞ –ø–æ—Ö–æ–∂–∏ –Ω–∞ 60% –∏ –±–æ–ª–µ–µ - —Å—á–∏—Ç–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏
        similarity = 1 - (distance / max_len)
        if similarity >= 0.6:
            return True

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è –ø–æ—Ö–æ–∂–µ –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—Ç—Å—è –ø–æ—Ö–æ–∂–µ
        if len(w1) >= 4 and len(w2) >= 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ö–æ—Ç—è –±—ã 3 –∏–∑ –ø–µ—Ä–≤—ã—Ö 4 –±—É–∫–≤ —Å–æ–≤–ø–∞–¥–∞—é—Ç
            matches = sum(1 for i in range(min(4, len(w1), len(w2))) if i < len(w1) and i < len(w2) and w1[i] == w2[i])
            if matches >= 3:
                return True

        return False

    def _remove_similar_duplicates(self, parts: list) -> list:
        """–£–¥–∞–ª—è–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤ (–æ—Å—Ç–∞–≤–ª—è–µ—Ç –±–æ–ª–µ–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç)"""
        if len(parts) <= 1:
            return parts

        cleaned = []
        skip_indices = set()

        for i, word in enumerate(parts):
            if i in skip_indices:
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–æ—Ö–æ–∂–µ–µ —Å–ª–æ–≤–æ –¥–∞–ª—å—à–µ
            found_similar = False
            for j in range(i + 1, len(parts)):
                if j in skip_indices:
                    continue

                if self._are_similar_words(word, parts[j]):
                    # –ù–∞—à–ª–∏ –ø–æ—Ö–æ–∂–µ–µ —Å–ª–æ–≤–æ - –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–µ–µ
                    # –ö—Ä–∏—Ç–µ—Ä–∏–π: —Å–ª–æ–≤–æ —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–≥–ª–∞–≤–Ω—ã—Ö –ª–∞—Ç–∏–Ω—Å–∫–∏—Ö –±—É–∫–≤
                    word_latin_count = sum(1 for c in word if c.isupper() and c.isalpha() and ord('A') <= ord(c) <= ord('Z'))
                    other_latin_count = sum(1 for c in parts[j] if c.isupper() and c.isalpha() and ord('A') <= ord(c) <= ord('Z'))

                    if other_latin_count > word_latin_count:
                        # –î—Ä—É–≥–æ–µ —Å–ª–æ–≤–æ –ª—É—á—à–µ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ–∫—É—â–µ–µ
                        skip_indices.add(i)
                        found_similar = True
                        break
                    else:
                        # –¢–µ–∫—É—â–µ–µ —Å–ª–æ–≤–æ –ª—É—á—à–µ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—Ä—É–≥–æ–µ
                        skip_indices.add(j)

            if not found_similar:
                cleaned.append(word)

        return cleaned

    def _smart_name_split(self, name_string: str) -> tuple:
        """–£–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∏–º–µ–Ω–∏ –Ω–∞ —Ñ–∞–º–∏–ª–∏—é –∏ –∏–º—è"""
        if not name_string:
            return ("", "")

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º
        parts = name_string.strip().split()

        if len(parts) == 0:
            return ("", "")

        # –£–¥–∞–ª—è–µ–º –ø–æ—Ö–æ–∂–∏–µ –¥—É–±–ª–∏–∫–∞—Ç—ã (OCR —á–∞—Å—Ç–æ –≤–∏–¥–∏—Ç –æ–¥–Ω–æ —Å–ª–æ–≤–æ –¥–≤–∞–∂–¥—ã)
        parts = self._remove_similar_duplicates(parts)

        if len(parts) == 0:
            return ("", "")
        elif len(parts) == 1:
            # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —Å–ª–æ–≤–æ - —Å—á–∏—Ç–∞–µ–º —Ñ–∞–º–∏–ª–∏–µ–π
            return (parts[0], "")
        else:
            # –ü–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ - —Ñ–∞–º–∏–ª–∏—è, –æ—Å—Ç–∞–ª—å–Ω—ã–µ - –∏–º—è
            last_name = parts[0]
            first_name = " ".join(parts[1:])
            return (last_name, first_name)

    def parse_mrz(self, text: str) -> dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ MRZ (Machine Readable Zone) - —Å—Ç—Ä–æ–∫–∞ –≤–Ω–∏–∑—É –ø–∞—Å–ø–æ—Ä—Ç–∞"""
        mrz_data = {}
        raw_lines = [line.strip().replace(" ", "") for line in text.splitlines()]
        # –†–∞—Å—à–∏—Ä—è–µ–º –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –≤ MRZ
        mrz_lines = [re.sub(r'[^A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9<]', '', line, flags=re.IGNORECASE) for line in raw_lines if len(re.sub(r'[^A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9<]', '', line, flags=re.IGNORECASE)) >= 25]

        if len(mrz_lines) < 2:
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω —Å –¥–≤–æ–π–Ω—ã–º–∏ —à–µ–≤—Ä–æ–Ω–∞–º–∏
            match = re.search(r'([A-Z]{2,})<<([A-Z]{2,})', text)
            if match:
                mrz_data["last_name"] = match.group(1).replace("<", "")
                mrz_data["first_name"] = match.group(2).replace("<", "")
                return mrz_data

            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω —Å –æ–¥–∏–Ω–∞—Ä–Ω—ã–º–∏ —à–µ–≤—Ä–æ–Ω–∞–º–∏ –∏–ª–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏
            match = re.search(r'([A-Z]{2,})\s+([A-Z]{2,})', text)
            if match:
                mrz_data["last_name"] = match.group(1)
                mrz_data["first_name"] = match.group(2)
            return mrz_data

        line1, line2 = mrz_lines[-2], mrz_lines[-1]
        if self.debug:
            print(f"‚úÖ MRZ —Å—Ç—Ä–æ–∫–∞ 1: {line1}")
            print(f"‚úÖ MRZ —Å—Ç—Ä–æ–∫–∞ 2: {line2}")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç MRZ
        if line1.startswith("P<"):
            # –§–æ—Ä–º–∞—Ç: P<XXX –≥–¥–µ XXX = –∫–æ–¥ —Å—Ç—Ä–∞–Ω—ã (3 –±—É–∫–≤—ã)
            # –ü–æ—Å–ª–µ –∫–æ–¥–∞ —Å—Ç—Ä–∞–Ω—ã –∏–¥–µ—Ç —Ñ–∞–º–∏–ª–∏—è
            if len(line1) > 5:
                # P< + 3 –±—É–∫–≤—ã –∫–æ–¥–∞ = 5 —Å–∏–º–≤–æ–ª–æ–≤
                name_field = line1[5:]
            else:
                name_field = line1[2:]  # Fallback: –ø—Ä–æ—Å—Ç–æ —É–±–∏—Ä–∞–µ–º P<
        else:
            name_field = line1

        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –¥–≤–æ–π–Ω—ã–º —à–µ–≤—Ä–æ–Ω–∞–º
        name_part = name_field.split("<<", 1)
        if name_part:
            mrz_data["last_name"] = name_part[0].replace("<", "")
            if len(name_part) > 1:
                # –£–±–∏—Ä–∞–µ–º –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ —à–µ–≤—Ä–æ–Ω—ã –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
                first_name_raw = name_part[1].replace("<", " ").strip()
                mrz_data["first_name"] = first_name_raw
            elif not mrz_data.get("first_name"):
                # –ï—Å–ª–∏ –Ω–µ—Ç –¥–≤–æ–π–Ω—ã—Ö —à–µ–≤—Ä–æ–Ω–æ–≤, –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ –æ–¥–∏–Ω–∞—Ä–Ω—ã–º
                name_parts = name_field.replace("<", " ").split()
                if len(name_parts) > 1:
                    mrz_data["last_name"] = name_parts[0]
                    mrz_data["first_name"] = " ".join(name_parts[1:])

        if len(line2) >= 9:
            mrz_doc = line2[0:9].replace("<", "")
            if mrz_doc:
                mrz_data["document_number"] = mrz_doc

        raw_exp = line2[21:27] if len(line2) >= 27 else ""
        exp_date = self._mrz_date_to_iso(raw_exp)
        if exp_date:
            mrz_data["expiration_date"] = exp_date

        return mrz_data

    def _mrz_date_to_iso(self, raw: str) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã MRZ YYMMDD -> DD.MM.YYYY"""
        if not raw or not raw.isdigit() or len(raw) != 6:
            return ""
        yy = int(raw[0:2])
        mm = int(raw[2:4])
        dd = int(raw[4:6])
        year = 2000 + yy
        current_year = datetime.now().year
        if year < current_year - 20:
            year += 100
        try:
            datetime(year, mm, dd)
            return f"{dd:02d}.{mm:02d}.{year}"
        except ValueError:
            return ""

    def parse_text(self, text: str) -> PassportData:
        """–û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ –ø–∞—Å–ø–æ—Ä—Ç–∞"""
        data = PassportData()

        if self.debug:
            print("\n" + "="*60)
            print("üîç –ù–ê–ß–ê–õ–û –ü–ê–†–°–ò–ù–ì–ê")
            print("="*60)

        # 1. –ò–ò–ù (12 —Ü–∏—Ñ—Ä –ø–æ–¥—Ä—è–¥)
        iin_match = re.search(r'\b(\d{12})\b', text)
        if iin_match:
            data.iin = iin_match.group(1)
            if self.debug:
                print(f"‚úÖ –ò–ò–ù: {data.iin}")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª –∏ –¥–∞—Ç—É —Ä–æ–∂–¥–µ–Ω–∏—è –∏–∑ –ò–ò–ù
            data.gender = self.get_gender_from_iin(data.iin)
            iin_dob = self.extract_date_from_iin(data.iin)
            if iin_dob and not data.dob:
                data.dob = iin_dob
                if self.debug:
                    print(f"‚úÖ –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è –∏–∑ –ò–ò–ù: {data.dob}")

        # 2. –ü–û–õ (–µ—Å–ª–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∏–∑ –ò–ò–ù)
        if not data.gender:
            # –ò—â–µ–º –ø–æ–ª –≤ —Ç–µ–∫—Å—Ç–µ
            gender_patterns = [
                r'(?:–ñ–´–ù–´–°–´|Sex|Gender)[\s:]*([–ú–ñMF–º–∂mf])',
                r'Sex[\s/]*([MF])',
                r'Gender[\s:]*([MF])',
            ]

            for pattern in gender_patterns:
                gender_match = re.search(pattern, text, re.IGNORECASE)
                if gender_match:
                    g = gender_match.group(1).upper()
                    if g in ['M', '–ú']:
                        data.gender = "M"
                    elif g in ['F', '–ñ']:
                        data.gender = "F"
                    if data.gender:
                        if self.debug:
                            print(f"‚úÖ –ü–æ–ª (—Ç–µ–∫—Å—Ç): {data.gender}")
                        break

        # 3. –ù–û–ú–ï–† –î–û–ö–£–ú–ï–ù–¢–ê (N + 8 —Ü–∏—Ñ—Ä)
        doc_patterns = [
            r'(N\d{8})',  # N12345678
            r'‚Ññ[\s]*([N–ê-–Ø0-9]{8,9})',  # ‚Ññ N12345678
            r'–ü–ê–°–ü–û–†–¢[^\n]*?([A-Z0-9]{8,9})',  # –ü–æ—Å–ª–µ —Å–ª–æ–≤–∞ –ü–ê–°–ü–û–†–¢
        ]

        for pattern in doc_patterns:
            doc_match = re.search(pattern, text)
            if doc_match:
                data.document_number = doc_match.group(1).strip()
                if self.debug:
                    print(f"‚úÖ –ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞: {data.document_number}")
                break

        # 4. –§–ê–ú–ò–õ–ò–Ø –ò –ò–ú–Ø
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —á–µ—Ä–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        surname_patterns = [
            r'(?:–¢–ï–ü\s*/?\s*–ó“∞“¢–ê–¢–ú–ï|–¢–ï–ü|–¢–ï–ì–Ü|Surname)[\s:]*\n+([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–ÅA-Z\s]+)',
            r'(?:Last\s*Name)[\s:]*\n+([A-Z\s]+)',
        ]

        raw_last_name = ""
        for pattern in surname_patterns:
            surname_match = re.search(pattern, text, re.IGNORECASE)
            if surname_match:
                raw_last_name = surname_match.group(1).strip()
                # –ü–∞—Ä—Å–∏–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –∏ –≤—ã–±–∏—Ä–∞–µ–º –ª–∞—Ç–∏–Ω–∏—Ü—É –µ—Å–ª–∏ –µ—Å—Ç—å
                lines = raw_last_name.split('\n')
                best_line = None
                for line in lines:
                    clean = line.strip()
                    if not clean or not re.match(r'^[A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å\s]+$', clean):
                        continue
                    # –°—á–∏—Ç–∞–µ–º –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã
                    latin_count = sum(1 for c in clean if c.isupper() and ord('A') <= ord(c) <= ord('Z'))
                    if best_line is None:
                        best_line = clean
                    elif latin_count > sum(1 for c in best_line if c.isupper() and ord('A') <= ord(c) <= ord('Z')):
                        best_line = clean  # –≠—Ç–æ –ª–∞—Ç–∏–Ω–∏—Ü–∞ - –ª—É—á—à–µ

                if best_line:
                    data.last_name = best_line
                    if self.debug:
                        print(f"‚úÖ –§–∞–º–∏–ª–∏—è: {data.last_name}")
                    break

        # –ò–º—è
        name_patterns = [
            r'(?:–ê–¢–´|Given\s*names?|First\s*Names?)[\s:]*\n+([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–ÅA-Z\s]+)',
            # –ë–æ–ª–µ–µ –≥–∏–±–∫–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω - –∏—â–µ–º GIVEN NAMES –¥–∞–∂–µ –µ—Å–ª–∏ –ø–µ—Ä–µ–¥ –Ω–∏–º –º—É—Å–æ—Ä
            r'GIVEN\s*NAMES?[\s:]*\n+([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–ÅA-Z\s]+)',
            # –ò—â–µ–º –ê–¢–´ + –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å—é —Å—Ç—Ä–æ–∫—É —Å –º—É—Å–æ—Ä–æ–º + –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º –∏–º—è –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–µ
            r'–ê–¢–´[^\n]*\n+([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å\s]+)',
        ]

        raw_first_name = ""
        for pattern in name_patterns:
            name_match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
            if name_match:
                name_text = name_match.group(1).strip()
                # –ü–∞—Ä—Å–∏–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –∏ –≤—ã–±–∏—Ä–∞–µ–º –ª–∞—Ç–∏–Ω–∏—Ü—É –µ—Å–ª–∏ –µ—Å—Ç—å
                lines = name_text.split('\n')
                best_name = None
                for line in lines:
                    clean_line = line.strip()
                    # –£–±–∏—Ä–∞–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –±—É–∫–≤—ã –≤ –Ω–∞—á–∞–ª–µ (–º—É—Å–æ—Ä OCR)
                    clean_line = re.sub(r'^[a-z–∞-—è”ô”©“Ø“±“ì“õ“£“ª—ñ—ë\s\d.!,;]+', '', clean_line).strip()
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ç–æ–ª—å–∫–æ –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã
                    if not clean_line or not re.match(r'^[A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å\s]+$', clean_line):
                        continue
                    # –°—á–∏—Ç–∞–µ–º –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã
                    latin_count = sum(1 for c in clean_line if c.isupper() and ord('A') <= ord(c) <= ord('Z'))
                    if best_name is None:
                        best_name = clean_line
                    elif latin_count > sum(1 for c in best_name if c.isupper() and ord('A') <= ord(c) <= ord('Z')):
                        best_name = clean_line  # –≠—Ç–æ –ª–∞—Ç–∏–Ω–∏—Ü–∞ - –ª—É—á—à–µ

                if best_name:
                    data.first_name = best_name
                    raw_first_name = best_name
                    if self.debug:
                        print(f"‚úÖ –ò–º—è: {data.first_name}")
                    break
                if data.first_name:
                    break

        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –≤–∑—è—Ç—å –ª–∞—Ç–∏–Ω—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ –∫–ª—é—á–µ–≤—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
        def pick_after(keyword: str):
            for idx, ln in enumerate(lines):
                if keyword in ln.upper():
                    for nxt in lines[idx+1:idx+4]:
                        cand = re.sub(r'[^A-Za-z]', '', nxt)
                        if cand and cand.isalpha() and not self._contains_cyrillic(nxt):
                            return cand
            return None

        surname_candidate = pick_after("SURNAME")
        if surname_candidate:
            data.last_name = surname_candidate
        name_candidate = pick_after("GIVEN")
        if name_candidate:
            data.first_name = name_candidate

        # –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–æ–ø–∞–ª–∏ –ª–∏ –æ–±–∞ –∏–º–µ–Ω–∏ –≤ –æ–¥–Ω–æ –ø–æ–ª–µ
        if data.last_name and not data.first_name:
            # –ï—Å–ª–∏ –≤ —Ñ–∞–º–∏–ª–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤, –≤–æ–∑–º–æ–∂–Ω–æ —Ç–∞–º –∏ –∏–º—è —Ç–æ–∂–µ
            if len(data.last_name.split()) > 1:
                if self.debug:
                    print(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≤ —Ñ–∞–º–∏–ª–∏–∏: {data.last_name}")
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —É–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
                split_last, split_first = self._smart_name_split(data.last_name)
                if split_first:  # –ï—Å–ª–∏ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å
                    data.last_name = split_last
                    data.first_name = split_first
                    if self.debug:
                        print(f"‚úÖ –ü–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è - –§–∞–º–∏–ª–∏—è: {data.last_name}, –ò–º—è: {data.first_name}")

        elif data.first_name and not data.last_name:
            # –ï—Å–ª–∏ –∏–º—è –µ—Å—Ç—å, –∞ —Ñ–∞–º–∏–ª–∏–∏ –Ω–µ—Ç - –≤–æ–∑–º–æ–∂–Ω–æ –≤—Å–µ –≤ –∏–º–µ–Ω–∏
            if len(data.first_name.split()) > 1:
                if self.debug:
                    print(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≤ –∏–º–µ–Ω–∏: {data.first_name}")
                split_last, split_first = self._smart_name_split(data.first_name)
                data.last_name = split_last
                data.first_name = split_first
                if self.debug:
                    print(f"‚úÖ –ü–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è - –§–∞–º–∏–ª–∏—è: {data.last_name}, –ò–º—è: {data.first_name}")

        # 5. –î–ê–¢–´
        # –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è
        if not data.dob:
            dob_patterns = [
                r'(?:–¢–£“í–ê–ù\s*–ö“Æ–ù–Ü|Date\s*of\s*birth|–î–∞—Ç–∞\s*—Ä–æ–∂–¥–µ–Ω–∏—è)[\s:]*(\d{2}[./]\d{2}[./]\d{4})',
                r'(?:Born|–†–æ–¥–∏–ª—Å—è)[\s:]*(\d{2}[./]\d{2}[./]\d{4})',
                r'(\d{2}\.\d{2}\.\d{4})',  # –ü—Ä–æ—Å—Ç–æ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã
            ]

            for pattern in dob_patterns:
                dob_match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
                if dob_match:
                    data.dob = dob_match.group(1).replace('/', '.')
                    if self.debug:
                        print(f"‚úÖ –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è: {data.dob}")
                    break

        # –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è
        exp_patterns = [
            r'(?:–ú–ï–†–ó–Ü–ú(?:–Ü)?|–ñ–ê–†–ê–ú–î–´\s*–î–û|Expiry|Expires|Valid\s*(?:until|to)|Date\s*of\s*Expiry|–î–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω\s*–¥–æ)[^\d]*(\d{2}\s*[./-]\s*\d{2}\s*[./-]\s*\d{4})',
            r'(?:Valid\s*until)[\s:]*(\d{2}\s*[./-]\s*\d{2}\s*[./-]\s*\d{4})',
            r'(?:–¥–æ\s*)(\d{2}\s*[./-]\s*\d{2}\s*[./-]\s*\d{4})',
        ]

        for pattern in exp_patterns:
            exp_match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if exp_match:
                data.expiration_date = self._clean_date(exp_match.group(1))
                if self.debug:
                    print(f"‚úÖ –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è: {data.expiration_date}")
                break

        # 6. MRZ OVERRIDE (—Å–∞–º—ã–π —Ç–æ—á–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–º–µ–Ω, –Ω–æ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π)
        mrz_data = self.parse_mrz(text)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—Ç–æ–∏—Ç –ª–∏ –¥–æ–≤–µ—Ä—è—Ç—å MRZ –¥–∞–Ω–Ω—ã–º
        use_mrz = False
        if mrz_data.get("last_name"):
            mrz_last = mrz_data["last_name"]
            mrz_first = mrz_data.get("first_name", "")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ MRZ: –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã
            mrz_last_latin = sum(1 for c in mrz_last if c.isalpha() and ord('A') <= ord(c.upper()) <= ord('Z'))
            mrz_last_cyrillic = sum(1 for c in mrz_last if c.isalpha() and not (ord('A') <= ord(c.upper()) <= ord('Z')))

            # –ï—Å–ª–∏ –≤ MRZ –±–æ–ª—å—à–µ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã, —á–µ–º –ª–∞—Ç–∏–Ω–∏—Ü—ã - —ç—Ç–æ –æ—à–∏–±–∫–∞ OCR
            if mrz_last_cyrillic > mrz_last_latin:
                if self.debug:
                    print(f"‚ö†Ô∏è MRZ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—É –≤–º–µ—Å—Ç–æ –ª–∞—Ç–∏–Ω–∏—Ü—ã: {mrz_last}")
                    print(f"   –õ–∞—Ç–∏–Ω–∏—Ü–∞: {mrz_last_latin}, –ö–∏—Ä–∏–ª–ª–∏—Ü–∞: {mrz_last_cyrillic}")
                    print(f"   –ü—Ä–æ–ø—É—Å–∫–∞–µ–º MRZ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è")
            else:
                # MRZ –≤—ã–≥–ª—è–¥–∏—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ - –∏—Å–ø–æ–ª—å–∑—É–µ–º
                use_mrz = True
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Å–ª–æ–≤–∞—Ä—è (—á—Ç–æ–±—ã —Ñ—Ä–æ–Ω—Ç –±—Ä–∞–ª –ª–∞—Ç–∏–Ω–∏—Ü—É)
                self.mrz_last_name = mrz_last
                self.mrz_first_name = mrz_first

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–æ–ø–∞–ª–∏ –ª–∏ –æ–±–∞ –∏–º–µ–Ω–∏ –≤ –æ–¥–Ω–æ –ø–æ–ª–µ
                if mrz_last and not mrz_first and len(mrz_last.split()) > 1:
                    if self.debug:
                        print(f"‚ö†Ô∏è MRZ: –ù–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≤ —Ñ–∞–º–∏–ª–∏–∏: {mrz_last}")
                    split_last, split_first = self._smart_name_split(mrz_last)
                    data.last_name = split_last
                    data.first_name = split_first
                    if self.debug:
                        print(f"‚úÖ MRZ –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è - –§–∞–º–∏–ª–∏—è: {data.last_name}, –ò–º—è: {data.first_name}")
                else:
                    data.last_name = mrz_last
                    if mrz_first:
                        data.first_name = mrz_first
                    if self.debug:
                        print(f"‚úÖ –§–∞–º–∏–ª–∏—è (MRZ override): {data.last_name}")
                        if mrz_first:
                            print(f"‚úÖ –ò–º—è (MRZ override): {data.first_name}")

        # –ï—Å–ª–∏ MRZ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, —É–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –µ—Å—Ç—å –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –∏–º–µ–Ω–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        if not use_mrz and self.debug:
            print(f"‚ÑπÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è –≤–º–µ—Å—Ç–æ MRZ")
            print(f"   –§–∞–º–∏–ª–∏—è: {data.last_name}")
            print(f"   –ò–º—è: {data.first_name}")

        # –ï—Å–ª–∏ MRZ –Ω–µ –ø–æ–¥–æ—à—ë–ª, –Ω–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ ‚Äî —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º
        if not use_mrz:
            if self._contains_cyrillic(data.last_name):
                data.last_name = self._transliterate(data.last_name)
            if self._contains_cyrillic(data.first_name):
                data.first_name = self._transliterate(data.first_name)

        if mrz_data.get("document_number") and not data.document_number:
            data.document_number = mrz_data["document_number"]
            if self.debug:
                print(f"‚úÖ –ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ (MRZ): {data.document_number}")
        if mrz_data.get("expiration_date") and not data.expiration_date:
            data.expiration_date = mrz_data["expiration_date"]
            if self.debug:
                print(f"‚úÖ –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è (MRZ): {data.expiration_date}")

        if not data.expiration_date:
            generic_matches = re.findall(r'(\d{2}(?:\s*[./-]\s*|\s+)\d{2}(?:\s*[./-]\s*|\s+)\d{4})', text)
            for match in reversed(generic_matches):
                cleaned = self._clean_date(match)
                if cleaned and cleaned != data.dob:
                    data.expiration_date = cleaned
                    if self.debug:
                        print(f"‚úÖ –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è (fallback): {data.expiration_date}")
                    break

        if self.debug:
            print("="*60)
            print(f"üìä –ò–¢–û–ì–û–í–´–ï –î–ê–ù–ù–´–ï:")
            print(f"   –§–∞–º–∏–ª–∏—è: {data.last_name}")
            print(f"   –ò–º—è: {data.first_name}")
            print(f"   –ü–æ–ª: {data.gender}")
            print(f"   –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è: {data.dob}")
            print(f"   –ò–ò–ù: {data.iin}")
            print(f"   –î–æ–∫—É–º–µ–Ω—Ç: {data.document_number}")
            print(f"   –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è: {data.expiration_date}")
            print(f"   –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å: {data.is_valid}")
            print("="*60 + "\n")

        return data

    def parse(self, file_path: str) -> PassportData:
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ñ–∞–π–ª–∞"""
        text = self.extract_ocr_text(file_path)
        return self.parse_text(text)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
def test_parser(file_path: str):
    parser = PassportParser(debug=True)
    result = parser.parse(file_path)
    print("\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢:")
    print(result.to_dict())
    return result
