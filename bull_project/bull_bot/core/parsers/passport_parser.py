import cv2
import pytesseract
import numpy as np
from pdf2image import convert_from_path
from PIL import Image
import os
import re
from dataclasses import dataclass
from datetime import datetime
import pdfplumber

@dataclass
class PassportData:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ø–∞—Å–ø–æ—Ä—Ç–∞"""
    last_name: str = ""
    first_name: str = ""
    gender: str = ""
    dob: str = ""
    iin: str = ""
    document_number: str = ""
    expiration_date: str = ""
    phone: str = ""  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–∞

    @property
    def full_name(self) -> str:
        return f"{self.last_name} {self.first_name}".strip()

    @property
    def is_valid(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö"""
        has_name = bool(self.last_name or self.first_name)
        has_iin = len(self.iin) == 12 if self.iin else False
        has_doc = bool(self.document_number)
        # –°—á–∏—Ç–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–º –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –∏–º—è –ò (–ò–ò–ù –ò–õ–ò –¥–æ–∫—É–º–µ–Ω—Ç)
        return has_name and (has_iin or has_doc)

    def to_dict(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è API"""
        return {
            "last_name": self.last_name or "-",
            "first_name": self.first_name or "-",
            "gender": self.gender or "M",
            "date_of_birth": self.dob or "-",
            "passport_num": self.document_number or "-",
            "phone": self.phone or "-",
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            "Last Name": self.last_name or "-",
            "First Name": self.first_name or "-",
            "Gender": self.gender or "M",
            "Date of Birth": self.dob or "-",
            "Document Number": self.document_number or "-",
            "Document Expiration": self.expiration_date or "-",
            "IIN": self.iin or "-",
            "MRZ_LAST": getattr(self, "mrz_last_name", None),
            "MRZ_FIRST": getattr(self, "mrz_first_name", None),
        }

class PassportParser:
    def __init__(self, poppler_path: str = None, debug: bool = False, save_ocr: bool = False):
        self.poppler_path = poppler_path
        self.debug = debug
        self.save_ocr = save_ocr  # –ù–æ–≤–∞—è –æ–ø—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è OCR —Ç–µ–∫—Å—Ç–∞
        self._date_cleaner = re.compile(r"\s+")
        self._digit_map = {"0": "O", "1": "I", "2": "Z", "3": "Z", "4": "A", "5": "S", "6": "G", "7": "T", "8": "B", "9": "P"}
        self._cyr_map = {
            "–ê": "A", "–ë": "B", "–í": "V", "–ì": "G", "–î": "D", "–ï": "E", "–Å": "E",
            "–ñ": "ZH", "–ó": "Z", "–ò": "I", "–ô": "Y", "–ö": "K", "–õ": "L", "–ú": "M",
            "–ù": "N", "–û": "O", "–ü": "P", "–†": "R", "–°": "S", "–¢": "T", "–£": "U",
            "–§": "F", "–•": "KH", "–¶": "TS", "–ß": "CH", "–®": "SH", "–©": "SCH",
            "–™": "", "–´": "Y", "–¨": "", "–≠": "E", "–Æ": "YU", "–Ø": "YA",
            "“ö": "K", "”ò": "A", "“¢": "N", "“í": "G", "“Æ": "U", "“∞": "U", "”®": "O", "“∫": "H", "–Ü": "I", "—ñ": "I",
            "–∞": "A", "–±": "B", "–≤": "V", "–≥": "G", "–¥": "D", "–µ": "E", "—ë": "E",
            "–∂": "ZH", "–∑": "Z", "–∏": "I", "–π": "Y", "–∫": "K", "–ª": "L", "–º": "M",
            "–Ω": "N", "–æ": "O", "–ø": "P", "—Ä": "R", "—Å": "S", "—Ç": "T", "—É": "U",
            "—Ñ": "F", "—Ö": "KH", "—Ü": "TS", "—á": "CH", "—à": "SH", "—â": "SCH",
            "—ä": "", "—ã": "Y", "—å": "", "—ç": "E", "—é": "YU", "—è": "YA",
            "“õ": "K", "”ô": "A", "“£": "N", "“ì": "G", "“Ø": "U", "“±": "U", "”©": "O", "“ª": "H",
        }

    def validate_iin_checksum(self, iin: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º—ã –ò–ò–ù –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞."""
        if not iin or len(iin) != 12 or not iin.isdigit():
            return False

        weights1 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
        checksum = sum(int(iin[i]) * weights1[i] for i in range(11)) % 11

        if checksum == 10:
            weights2 = [3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2]
            checksum = sum(int(iin[i]) * weights2[i] for i in range(11)) % 11

        return checksum == int(iin[11])

    def _calculate_mrz_check_digit(self, data: str) -> int:
        """–†–∞—Å—á–µ—Ç –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ü–∏—Ñ—Ä—ã MRZ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç ICAO)."""
        weights = [7, 3, 1]
        total = 0
        for i, char in enumerate(data):
            if char == '<':
                val = 0
            elif '0' <= char <= '9':
                val = ord(char) - ord('0')
            elif 'A' <= char <= 'Z':
                val = ord(char) - ord('A') + 10
            else:
                val = 0
            total += val * weights[i % 3]
        return total % 10

    def _clean_date(self, value: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏."""
        if not value:
            return ""
        stripped = self._date_cleaner.sub("", value)
        stripped = stripped.replace('/', '.').replace('-', '.')
        if len(stripped) == 8 and stripped.isdigit():
            return f"{stripped[0:2]}.{stripped[2:4]}.{stripped[4:]}"
        return stripped

    def _contains_cyrillic(self, value: str) -> bool:
        return any("–ê" <= c <= "—è" or c in "–Å—ë“ö“õ”ò”ô“¢“£“í“ì“Æ“Ø“∞“±”®”©“∫“ª" for c in value or "")

    def _transliterate(self, value: str) -> str:
        if not value:
            return ""
        return "".join(self._cyr_map.get(ch, ch) for ch in value)

    def _normalize_token(self, value: str) -> str:
        """
        –ü—Ä–∏–≤–æ–¥–∏—Ç –∏–º—è/—Ñ–∞–º–∏–ª–∏—é –∫ –ª–∞—Ç–∏–Ω–∏—Ü–µ, —É–±–∏—Ä–∞–µ—Ç —à—É–º –∏ OCR-—Ü–∏—Ñ—Ä—ã.
        """
        if not value:
            return ""
        # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
        value = self._transliterate(value)
        # –ó–∞–º–µ–Ω—è–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ü–∏—Ñ—Ä—ã –Ω–∞ –±—É–∫–≤—ã
        value = "".join(self._digit_map.get(ch, ch) for ch in value)
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω–∏—Ü—É –∏ –ø—Ä–æ–±–µ–ª—ã
        value = re.sub(r"[^A-Z\s]", "", value.upper())
        return value.strip()

    def preprocess_image(self, image: Image.Image, aggressive: bool = False) -> np.ndarray:
        """–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

        Args:
            image: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            aggressive: –ï—Å–ª–∏ True, –ø—Ä–∏–º–µ–Ω—è–µ—Ç –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è MRZ
        """
        img = np.array(image)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if len(img.shape) == 3:
            if img.shape[2] == 4:  # RGBA
                gray = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)
            elif img.shape[2] == 3:  # RGB –∏–ª–∏ BGR
                gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            else:
                gray = img
        elif len(img.shape) == 2:
            # –£–∂–µ grayscale
            gray = img
        else:
            gray = img

        if aggressive:
            # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è MRZ
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–µ–∑–∫–æ—Å—Ç—å
            kernel_sharpen = np.array([[-1,-1,-1],
                                      [-1, 9,-1],
                                      [-1,-1,-1]])
            gray = cv2.filter2D(gray, -1, kernel_sharpen)

            # –ë–æ–ª–µ–µ —Å–∏–ª—å–Ω—ã–π CLAHE
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4, 4))
            enhanced = clahe.apply(gray)

            # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —à—É–º–∞
            kernel = np.ones((2, 2), np.uint8)
            enhanced = cv2.morphologyEx(enhanced, cv2.MORPH_CLOSE, kernel)

            # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
            binary = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                          cv2.THRESH_BINARY, 11, 2)
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            enhanced = clahe.apply(gray)
            _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

        return binary

    def extract_mrz_from_image(self, pil_image: Image.Image) -> str:
        """–°–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ MRZ –∑–æ–Ω—ã —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º OCR

        Args:
            pil_image: PIL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–∞—Å–ø–æ—Ä—Ç–∞

        Returns:
            –¢–µ–∫—Å—Ç MRZ –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        """
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy
            img = np.array(pil_image)

            # –ï—Å–ª–∏ —ç—Ç–æ RGB/RGBA, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale —Å–Ω–∞—á–∞–ª–∞
            if len(img.shape) == 3:
                if img.shape[2] == 4:  # RGBA
                    img = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)
                elif img.shape[2] == 3:  # RGB
                    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

            height, width = img.shape[:2]

            # –í—ã—Ä–µ–∑–∞–µ–º –Ω–∏–∂–Ω–∏–µ 20% –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–≥–¥–µ –æ–±—ã—á–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è MRZ)
            # –£–≤–µ–ª–∏—á–∏–ª —Å 15% –¥–æ 20% –¥–ª—è –±–æ–ª—å—à–µ–π –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
            mrz_region = img[int(height * 0.80):, :]

            if self.debug:
                print(f"üîç MRZ —Ä–µ–≥–∏–æ–Ω: {mrz_region.shape}, –¥–∏–∞–ø–∞–∑–æ–Ω: {int(height * 0.80)} - {height}")

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ PIL –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
            mrz_pil = Image.fromarray(mrz_region)

            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            processed_variants = []

            # 1. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            try:
                processed_variants.append(self.preprocess_image(mrz_pil, aggressive=False))
            except:
                pass

            # 2. –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            try:
                processed_variants.append(self.preprocess_image(mrz_pil, aggressive=True))
            except:
                pass

            # 3. –ë–µ–∑ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Ç–æ–ª—å–∫–æ grayscale)
            try:
                processed_variants.append(mrz_region)
            except:
                pass

            # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏: –æ–±—Ä–∞–±–æ—Ç–∫–∞ + –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è OCR
            configs = [
                '--psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789<',  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è
                '--psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789<',  # –û–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞
                '--psm 6',  # –ë–µ–∑ whitelist
            ]

            best_text = ""
            for processed_img in processed_variants:
                for config in configs:
                    try:
                        mrz_text = pytesseract.image_to_string(
                            processed_img,
                            lang="eng",  # –¢–æ–ª—å–∫–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π!
                            config=config
                        )
                        # –í—ã–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —à–µ–≤—Ä–æ–Ω–æ–≤ –∏–ª–∏ –ª–∞—Ç–∏–Ω—Å–∫–∏—Ö –±—É–∫–≤
                        score = mrz_text.count('<') * 2 + sum(1 for c in mrz_text if c.isalpha() and c.isupper())
                        best_score = best_text.count('<') * 2 + sum(1 for c in best_text if c.isalpha() and c.isupper())
                        if score > best_score:
                            best_text = mrz_text
                    except:
                        continue

            if self.debug:
                print(f"üîç MRZ OCR (—Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π):")
                print(best_text[:300] if len(best_text) > 300 else best_text)

            return best_text

        except Exception as e:
            if self.debug:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ MRZ: {e}")
            import traceback
            traceback.print_exc()
            return ""

    def _is_ocr_quality_good(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ OCR —Ç–µ–∫—Å—Ç–∞ - –µ—Å—Ç—å –ª–∏ –≤ –Ω–µ–º —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–µ"""
        if not text or len(text) < 20:
            return False

        # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—É–∫–≤ (–ª–∞—Ç–∏–Ω–∏—Ü–∞ + –∫–∏—Ä–∏–ª–ª–∏—Ü–∞)
        letters = sum(1 for c in text if c.isalpha())
        # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º—É—Å–æ—Ä–∞ (–Ω–µ –±—É–∫–≤—ã, –Ω–µ —Ü–∏—Ñ—Ä—ã, –Ω–µ –ø—Ä–æ–±–µ–ª—ã, –Ω–µ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è)
        total_chars = len(text.replace(" ", "").replace("\n", ""))

        if total_chars == 0:
            return False

        # –ï—Å–ª–∏ –º–µ–Ω—å—à–µ 40% —Ç–µ–∫—Å—Ç–∞ - –±—É–∫–≤—ã, —ç—Ç–æ –º—É—Å–æ—Ä
        letter_ratio = letters / total_chars
        if letter_ratio < 0.4:
            return False

        # –ò—â–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ (–º–∏–Ω–∏–º—É–º 4 –±—É–∫–≤—ã –ø–æ–¥—Ä—è–¥)
        words = re.findall(r'[A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å]{4,}', text, re.IGNORECASE)
        if len(words) < 3:  # –ú–∏–Ω–∏–º—É–º 3 —Å–ª–æ–≤–∞
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —è–≤–Ω—ã–π –º—É—Å–æ—Ä: —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –±—É–∫–≤ –∏ —Ü–∏—Ñ—Ä
        single_chars = re.findall(r'\b[A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9]\b', text, re.IGNORECASE)
        if len(single_chars) > len(words) * 2:  # –ï—Å–ª–∏ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –±–æ–ª—å—à–µ —á–µ–º –≤ 2 —Ä–∞–∑–∞
            return False

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –∏—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –ø–∞—Å–ø–æ—Ä—Ç–∞
        # –•–æ—Ä–æ—à–∏–π OCR –¥–æ–ª–∂–µ–Ω —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∏–∑ —ç—Ç–∏—Ö —Å–ª–æ–≤
        passport_keywords = [
            'PASSPORT', '–ü–ê–°–ü–û–†–¢', 'SURNAME', '–§–ê–ú–ò–õ–ò–Ø', 'NAME', '–ò–ú–Ø',
            'NATIONALITY', 'KAZAKHSTAN', '–ö–ê–ó–ê–•–°–¢–ê–ù', 'DATE', 'BIRTH'
        ]
        found_keywords = sum(1 for kw in passport_keywords if kw in text.upper())

        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –º–µ–Ω—å—à–µ 2 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –º—É—Å–æ—Ä
        if found_keywords < 2:
            return False

        return True

    def extract_ocr_text(self, file_path: str) -> tuple:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Tesseract —Å fallback –Ω–∞ pdfplumber

        Returns:
            tuple: (–æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç, MRZ —Ç–µ–∫—Å—Ç –∏–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ OCR)
        """
        try:
            if file_path.lower().endswith('.pdf'):
                pages = convert_from_path(file_path, dpi=300, poppler_path=self.poppler_path)
                if not pages:
                    return "", ""
                pil_image = pages[0]
            else:
                pil_image = Image.open(file_path)

            # 1. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π OCR –¥–ª—è –≤—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            processed_img = self.preprocess_image(pil_image)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —è–∑—ã–∫–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            text = pytesseract.image_to_string(
                processed_img,
                lang="kaz+rus+eng",
                config='--psm 6'  # Assume uniform block of text
            )

            # –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º OCR —Ç–µ–∫—Å—Ç –≤ —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            if self.save_ocr or self.debug:
                ocr_file = file_path + ".ocr_text.txt"
                with open(ocr_file, "w", encoding="utf-8") as f:
                    f.write(text)
                print(f"üíæ OCR —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {ocr_file}")

            if self.debug:
                print("üìÑ OCR TEXT START" + "="*40)
                print(text)
                print("="*40 + " OCR TEXT END")

            # 2. –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π OCR –¥–ª—è MRZ –∑–æ–Ω—ã (—Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω–∏—Ü–∞)
            mrz_text = self.extract_mrz_from_image(pil_image)

            # 3. FALLBACK: –ï—Å–ª–∏ OCR –¥–∞–ª –ø–ª–æ—Ö–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ —ç—Ç–æ PDF - –ø—Ä–æ–±—É–µ–º pdfplumber
            if not self._is_ocr_quality_good(text) and file_path.lower().endswith('.pdf'):
                if self.debug:
                    print("‚ö†Ô∏è OCR –¥–∞–ª –ø–ª–æ—Ö–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –Ω–∞–ø—Ä—è–º—É—é –∏–∑ PDF...")

                try:
                    with pdfplumber.open(file_path) as pdf:
                        if pdf.pages:
                            pdf_text = pdf.pages[0].extract_text()
                            if pdf_text and len(pdf_text) > len(text):
                                if self.debug:
                                    print("‚úÖ PDF —Ç–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω —É—Å–ø–µ—à–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –≤–º–µ—Å—Ç–æ OCR")
                                    print("üìÑ PDF TEXT START" + "="*40)
                                    print(pdf_text)
                                    print("="*40 + " PDF TEXT END")
                                text = pdf_text
                                # –î–ª—è PDF —Ç–µ–∫—Å—Ç–∞ –Ω–µ –Ω—É–∂–µ–Ω —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π MRZ OCR, –æ–Ω —É–∂–µ –µ—Å—Ç—å –≤ —Ç–µ–∫—Å—Ç–µ
                except Exception as e:
                    if self.debug:
                        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ PDF: {e}")

            return text, mrz_text
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ OCR: {e}")
            return "", ""

    def get_gender_from_iin(self, iin: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∞ –ø–æ 7-–π —Ü–∏—Ñ—Ä–µ –ò–ò–ù"""
        if not iin or len(iin) != 12 or not iin.isdigit():
            return ""
        digit = int(iin[6])
        return "M" if digit in [1, 3, 5] else "F" if digit in [2, 4, 6] else ""

    def extract_date_from_iin(self, iin: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç—ã —Ä–æ–∂–¥–µ–Ω–∏—è –∏–∑ –ò–ò–ù (–ø–µ—Ä–≤—ã–µ 6 —Ü–∏—Ñ—Ä - YYMMDD)"""
        if not iin or len(iin) < 6 or not iin[:6].isdigit():
            return ""

        try:
            yy = int(iin[0:2])
            mm = int(iin[2:4])
            dd = int(iin[4:6])

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–µ–∫ –ø–æ 7-–π —Ü–∏—Ñ—Ä–µ
            century_digit = int(iin[6]) if len(iin) > 6 else 0
            if century_digit in [1, 2]:
                year = 1800 + yy
            elif century_digit in [3, 4]:
                year = 1900 + yy
            elif century_digit in [5, 6]:
                year = 2000 + yy
            else:
                year = 1900 + yy  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 1900-–µ

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –¥–∞—Ç—ã
            datetime(year, mm, dd)

            return f"{dd:02d}.{mm:02d}.{year}"
        except (ValueError, IndexError):
            return ""

    def _levenshtein_distance(self, s1: str, s2: str) -> int:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞ –º–µ–∂–¥—É –¥–≤—É–º—è —Å—Ç—Ä–æ–∫–∞–º–∏"""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)

        if len(s2) == 0:
            return len(s1)

        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row

        return previous_row[-1]

    def _are_similar_words(self, word1: str, word2: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ—Ö–æ–∂–∏ –ª–∏ –¥–≤–∞ —Å–ª–æ–≤–∞ (–≤–æ–∑–º–æ–∂–Ω–æ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç - –æ—à–∏–±–∫–∞ OCR)"""
        if not word1 or not word2:
            return False

        w1, w2 = word1.upper(), word2.upper()
        if w1 == w2:
            return True

        # –°–ª–æ–≤–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–Ω–æ–π –¥–ª–∏–Ω—ã
        if abs(len(w1) - len(w2)) > 3:
            return False

        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞
        distance = self._levenshtein_distance(w1, w2)
        max_len = max(len(w1), len(w2))

        # –ï—Å–ª–∏ —Å–ª–æ–≤–∞ –ø–æ—Ö–æ–∂–∏ –Ω–∞ 60% –∏ –±–æ–ª–µ–µ - —Å—á–∏—Ç–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏
        similarity = 1 - (distance / max_len)
        if similarity >= 0.6:
            return True

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è –ø–æ—Ö–æ–∂–µ –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—Ç—Å—è –ø–æ—Ö–æ–∂–µ
        if len(w1) >= 4 and len(w2) >= 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ö–æ—Ç—è –±—ã 3 –∏–∑ –ø–µ—Ä–≤—ã—Ö 4 –±—É–∫–≤ —Å–æ–≤–ø–∞–¥–∞—é—Ç
            matches = sum(1 for i in range(min(4, len(w1), len(w2))) if i < len(w1) and i < len(w2) and w1[i] == w2[i])
            if matches >= 3:
                return True

        return False

    def _remove_similar_duplicates(self, parts: list) -> list:
        """–£–¥–∞–ª—è–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤ (–æ—Å—Ç–∞–≤–ª—è–µ—Ç –±–æ–ª–µ–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç)"""
        if len(parts) <= 1:
            return parts

        cleaned = []
        skip_indices = set()

        for i, word in enumerate(parts):
            if i in skip_indices:
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–æ—Ö–æ–∂–µ–µ —Å–ª–æ–≤–æ –¥–∞–ª—å—à–µ
            found_similar = False
            for j in range(i + 1, len(parts)):
                if j in skip_indices:
                    continue

                if self._are_similar_words(word, parts[j]):
                    # –ù–∞—à–ª–∏ –ø–æ—Ö–æ–∂–µ–µ —Å–ª–æ–≤–æ - –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–µ–µ
                    # –ö—Ä–∏—Ç–µ—Ä–∏–π: —Å–ª–æ–≤–æ —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–≥–ª–∞–≤–Ω—ã—Ö –ª–∞—Ç–∏–Ω—Å–∫–∏—Ö –±—É–∫–≤
                    word_latin_count = sum(1 for c in word if c.isupper() and c.isalpha() and ord('A') <= ord(c) <= ord('Z'))
                    other_latin_count = sum(1 for c in parts[j] if c.isupper() and c.isalpha() and ord('A') <= ord(c) <= ord('Z'))

                    if other_latin_count > word_latin_count:
                        # –î—Ä—É–≥–æ–µ —Å–ª–æ–≤–æ –ª—É—á—à–µ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ–∫—É—â–µ–µ
                        skip_indices.add(i)
                        found_similar = True
                        break
                    else:
                        # –¢–µ–∫—É—â–µ–µ —Å–ª–æ–≤–æ –ª—É—á—à–µ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—Ä—É–≥–æ–µ
                        skip_indices.add(j)

            if not found_similar:
                cleaned.append(word)

        return cleaned

    def _smart_name_split(self, name_string: str) -> tuple:
        """–£–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∏–º–µ–Ω–∏ –Ω–∞ —Ñ–∞–º–∏–ª–∏—é –∏ –∏–º—è"""
        if not name_string:
            return ("", "")

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º
        parts = name_string.strip().split()

        if len(parts) == 0:
            return ("", "")

        # –£–¥–∞–ª—è–µ–º –ø–æ—Ö–æ–∂–∏–µ –¥—É–±–ª–∏–∫–∞—Ç—ã (OCR —á–∞—Å—Ç–æ –≤–∏–¥–∏—Ç –æ–¥–Ω–æ —Å–ª–æ–≤–æ –¥–≤–∞–∂–¥—ã)
        parts = self._remove_similar_duplicates(parts)

        if len(parts) == 0:
            return ("", "")
        elif len(parts) == 1:
            # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —Å–ª–æ–≤–æ - —Å—á–∏—Ç–∞–µ–º —Ñ–∞–º–∏–ª–∏–µ–π
            return (parts[0], "")
        else:
            # –ü–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ - —Ñ–∞–º–∏–ª–∏—è, –æ—Å—Ç–∞–ª—å–Ω—ã–µ - –∏–º—è
            last_name = parts[0]
            first_name = " ".join(parts[1:])
            return (last_name, first_name)

    def _name_quality(self, value: str) -> float:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏–º–µ–Ω–∏/—Ñ–∞–º–∏–ª–∏–∏: —à—Ç—Ä–∞—Ñ—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –æ–±—Ä–µ–∑–∫–∏ –∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤.
        –ù—É–∂–Ω–æ, —á—Ç–æ–±—ã MRZ –º–æ–≥ –ø–µ—Ä–µ–∫—Ä—ã—Ç—å —à—É–º–Ω—ã–π —Ç–µ–∫—Å—Ç –≤—Ä–æ–¥–µ "A Z AF OO".
        """
        if not value:
            return 0.0
        tokens = [t for t in value.split() if t]
        if not tokens:
            return 0.0

        score = sum(len(t) for t in tokens)
        short_tokens = sum(1 for t in tokens if len(t) <= 2)
        score -= short_tokens * 1.5
        if len(tokens) > 2:
            score -= (len(tokens) - 2) * 0.5
        if not all(t.isalpha() for t in tokens):
            score -= 1

        return score

    def _remove_noise_tokens(self, value: str) -> str:
        """–£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞, –ø–æ–ø–∞–≤—à–∏–µ –≤ –∏—Ç–æ–≥–æ–≤—ã–µ –∏–º–µ–Ω–∞."""
        if not value:
            return ""
        noise = {
            "SURNAME", "GIVEN", "NAMES", "GIVENNAMES", "FIRST", "NAME",
            "DATE", "OF", "BIRTH",
        }
        tokens = [t for t in value.split() if t]
        filtered = [t for t in tokens if t.upper() not in noise]
        return " ".join(filtered).strip()

    def _looks_like_noise_name(self, value: str) -> bool:
        """–≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è —è–≤–Ω–æ–≥–æ —à—É–º–∞ (–∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ª–∏–ø—à–∏–µ—Å—è —Å–ª–æ–≤–∞)."""
        if not value:
            return False
        up = value.upper()
        noise_fragments = ["SURNAME", "GIVEN", "NAME", "NAMES", "FIRST", "PASSPORT"]
        if any(n in up for n in noise_fragments):
            return True
        # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –≥–ª–∞—Å–Ω—ã—Ö
        vowels = sum(1 for c in up if c in "AEIOUY")
        if vowels == 0 and len(up) > 4:
            return True
        # –ï—Å–ª–∏ –æ–¥–Ω–æ —Å–ª–æ–≤–æ –¥–ª–∏–Ω–Ω–µ–µ 10 –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ –º–µ–Ω—å—à–µ 3 –ø–æ–≤—Ç–æ—Ä–æ–≤ –æ–¥–Ω–æ–π –±—É–∫–≤—ã
        if " " not in value and len(up) >= 10 and max(up.count(c) for c in set(up)) >= 3:
            return True
        return False

    def parse_mrz(self, text: str, mrz_specialized_text: str = "") -> dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ MRZ (Machine Readable Zone) - —Å—Ç—Ä–æ–∫–∞ –≤–Ω–∏–∑—É –ø–∞—Å–ø–æ—Ä—Ç–∞

        Args:
            text: –û—Å–Ω–æ–≤–Ω–æ–π OCR —Ç–µ–∫—Å—Ç
            mrz_specialized_text: –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π OCR —Ç–æ–ª—å–∫–æ –¥–ª—è MRZ –∑–æ–Ω—ã (—Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω–∏—Ü–∞)
        """
        mrz_data = {}

        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π MRZ —Ç–µ–∫—Å—Ç - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å
        if mrz_specialized_text and self.debug:
            print(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π MRZ OCR (—Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω–∏—Ü–∞)")

        # –ü—Ä–æ–±—É–µ–º —Å–Ω–∞—á–∞–ª–∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –ø–æ—Ç–æ–º –æ—Å–Ω–æ–≤–Ω–æ–π
        text_to_parse = mrz_specialized_text if mrz_specialized_text else text

        raw_lines = [line.strip().replace(" ", "") for line in text_to_parse.splitlines()]

        # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç - —Ä–∞–∑—Ä–µ—à–∞–µ–º —Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω–∏—Ü—É
        if mrz_specialized_text:
            # –¢–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω–∏—Ü–∞, —Ü–∏—Ñ—Ä—ã –∏ <
            mrz_lines = [re.sub(r'[^A-Z0-9<]', '', line, flags=re.IGNORECASE) for line in raw_lines if len(re.sub(r'[^A-Z0-9<]', '', line, flags=re.IGNORECASE)) >= 25]
        else:
            # –†–∞—Å—à–∏—Ä—è–µ–º –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –≤ MRZ (fallback)
            mrz_lines = [re.sub(r'[^A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9<]', '', line, flags=re.IGNORECASE) for line in raw_lines if len(re.sub(r'[^A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9<]', '', line, flags=re.IGNORECASE)) >= 25]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ MRZ —Å—Ç—Ä–æ–∫ - –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ–º —è–≤–Ω—ã–π –º—É—Å–æ—Ä
        if len(mrz_lines) >= 2:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å–ª–æ–≤ (–ø—Ä–∏–∑–Ω–∞–∫ —á—Ç–æ —ç—Ç–æ –Ω–µ MRZ)
            noise_words = ["MINISTRY", "INTERNAL", "AFFAIRS", "PASSPORT", "NATIONALITY", "REPUBLIC"]
            line1_upper = mrz_lines[0].upper() if mrz_lines else ""
            is_noise = any(word in line1_upper for word in noise_words)

            if is_noise:
                if self.debug:
                    print(f"‚ö†Ô∏è MRZ —Å—Ç—Ä–æ–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞ (–Ω–µ –Ω–∞—Å—Ç–æ—è—â–∏–π MRZ), –∏—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
                mrz_lines = []  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —á—Ç–æ–±—ã –ø–µ—Ä–µ–π—Ç–∏ –∫ –ø–æ–∏—Å–∫—É –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

        if len(mrz_lines) < 2:
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω —Å —à–µ–≤—Ä–æ–Ω–∞–º–∏ (OCR –º–æ–∂–µ—Ç –≤–∏–¥–µ—Ç—å << –∫–∞–∫ < <, \< < –∏ —Ç.–¥.)
            # –ò—â–µ–º –≤ –ò–°–•–û–î–ù–û–ú —Ç–µ–∫—Å—Ç–µ (–≤–∫–ª—é—á–∞—è –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏)
            patterns = [
                r'([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9]{3,})\s*<<\s*([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9]{3,})',  # —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π <<
                r'([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9]{3,})\s*<\s*<\s*([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9]{3,})',  # < <
                r'([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9]{3,})\\<\s*<\s*([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9]{3,})',  # \< <
                r'([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9]{3,})<\s+<\s*([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9]{3,})',  # < <
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–ª–æ—Ö–∏—Ö —Å–∫–∞–Ω–æ–≤ (—Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –∏–º—è —Å —à–µ–≤—Ä–æ–Ω–∞–º–∏)
                r'([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å]{4,})\s*<{3,}',  # –ò–º—è —Å –º–∏–Ω–∏–º—É–º 3 —à–µ–≤—Ä–æ–Ω–∞–º–∏ (FATULLA <<<<)
            ]

            for pattern in patterns:
                match = re.search(pattern, text_to_parse, re.IGNORECASE)
                if match:
                    last_name = match.group(1).replace("<", "").replace("\\", "").strip()
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –≤—Ç–æ—Ä–∞—è –≥—Ä—É–ø–ø–∞ (–∏–º—è)
                    try:
                        first_name = match.group(2).replace("<", "").replace("\\", "").strip()
                    except IndexError:
                        # –ü–∞—Ç—Ç–µ—Ä–Ω –Ω–∞—à—ë–ª —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —Å–ª–æ–≤–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä FATULLA <<<<)
                        # –ü–æ–∫–∞ –Ω–µ —è—Å–Ω–æ —ç—Ç–æ —Ñ–∞–º–∏–ª–∏—è –∏–ª–∏ –∏–º—è - —Å–æ—Ö—Ä–∞–Ω–∏–º –∫–∞–∫ –∏–º—è
                        first_name = last_name
                        last_name = ""

                    if self.debug:
                        print(f"  üìç –ù–∞–π–¥–µ–Ω MRZ –ø–∞—Ç—Ç–µ—Ä–Ω:")
                        print(f"     –ò—Å—Ö–æ–¥–Ω–∞—è —Ñ–∞–º–∏–ª–∏—è: '{last_name}'")
                        print(f"     –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–º—è:     '{first_name}'")

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü—É –∏ —Ü–∏—Ñ—Ä—ã (–ø—Ä–∏–∑–Ω–∞–∫ –æ—à–∏–±–æ–∫ OCR)
                    last_had_issues = self._contains_cyrillic(last_name) or any(c.isdigit() for c in last_name)
                    first_had_issues = self._contains_cyrillic(first_name) or any(c.isdigit() for c in first_name)

                    # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º –µ—Å–ª–∏ –∫–∏—Ä–∏–ª–ª–∏—Ü–∞
                    if self._contains_cyrillic(last_name):
                        if self.debug:
                            print(f"     ‚ö†Ô∏è  –§–∞–º–∏–ª–∏—è –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ, —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º...")
                        last_name = self._transliterate(last_name)
                    last_name = self._normalize_token(last_name)
                    if self.debug:
                        print(f"     ‚úÖ –ü–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏: '{last_name}'")

                    if self._contains_cyrillic(first_name):
                        if self.debug:
                            print(f"     ‚ö†Ô∏è  –ò–º—è –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ, —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º...")
                        first_name = self._transliterate(first_name)
                    first_name = self._normalize_token(first_name)
                    if self.debug:
                        print(f"     ‚úÖ –ü–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏: '{first_name}'")

                    mrz_data["last_name"] = last_name
                    mrz_data["first_name"] = first_name
                    mrz_data["last_had_issues"] = last_had_issues
                    mrz_data["first_had_issues"] = first_had_issues
                    if self.debug:
                        print(f"‚úÖ MRZ (pattern): {mrz_data['last_name']} {mrz_data.get('first_name', '')}")
                    return mrz_data

            return mrz_data

        line1, line2 = mrz_lines[-2], mrz_lines[-1]
        if self.debug:
            print(f"‚úÖ MRZ —Å—Ç—Ä–æ–∫–∞ 1 (raw): {line1}")
            print(f"‚úÖ MRZ —Å—Ç—Ä–æ–∫–∞ 2 (raw): {line2}")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç MRZ
        if line1.startswith("P<"):
            # –§–æ—Ä–º–∞—Ç: P<XXX –≥–¥–µ XXX = –∫–æ–¥ —Å—Ç—Ä–∞–Ω—ã (3 –±—É–∫–≤—ã)
            # –ü–æ—Å–ª–µ –∫–æ–¥–∞ —Å—Ç—Ä–∞–Ω—ã –∏–¥–µ—Ç —Ñ–∞–º–∏–ª–∏—è
            if len(line1) > 5:
                # P< + 3 –±—É–∫–≤—ã –∫–æ–¥–∞ = 5 —Å–∏–º–≤–æ–ª–æ–≤
                name_field = line1[5:]
            else:
                name_field = line1[2:]  # Fallback: –ø—Ä–æ—Å—Ç–æ —É–±–∏—Ä–∞–µ–º P<
        else:
            name_field = line1

        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –¥–≤–æ–π–Ω—ã–º —à–µ–≤—Ä–æ–Ω–∞–º
        name_part = name_field.split("<<", 1)
        if name_part:
            last_name_raw = name_part[0].replace("<", "")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü—É –∏ —Ü–∏—Ñ—Ä—ã (–ø—Ä–∏–∑–Ω–∞–∫ –æ—à–∏–±–æ–∫ OCR)
            last_had_issues = self._contains_cyrillic(last_name_raw) or any(c.isdigit() for c in last_name_raw)

            # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º –µ—Å–ª–∏ –∫–∏—Ä–∏–ª–ª–∏—Ü–∞
            if self._contains_cyrillic(last_name_raw):
                if self.debug:
                    print(f"‚ö†Ô∏è MRZ —Ñ–∞–º–∏–ª–∏—è –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ: {last_name_raw}")
            last_name_raw = self._transliterate(last_name_raw)
            last_name_raw = self._normalize_token(last_name_raw)
            if self.debug:
                print(f"‚úÖ –ü–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏: {last_name_raw}")
            mrz_data["last_name"] = last_name_raw
            mrz_data["last_had_issues"] = last_had_issues

            first_had_issues = False
            if len(name_part) > 1:
                # –£–±–∏—Ä–∞–µ–º –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ —à–µ–≤—Ä–æ–Ω—ã –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
                first_name_raw = name_part[1].replace("<", " ").strip()
                first_had_issues = self._contains_cyrillic(first_name_raw) or any(c.isdigit() for c in first_name_raw)
                if self._contains_cyrillic(first_name_raw):
                    if self.debug:
                        print(f"‚ö†Ô∏è MRZ –∏–º—è –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ: {first_name_raw}")
                first_name_raw = self._transliterate(first_name_raw)
                first_name_raw = self._normalize_token(first_name_raw)
                if self.debug:
                    print(f"‚úÖ –ü–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏: {first_name_raw}")
                mrz_data["first_name"] = first_name_raw
                mrz_data["first_had_issues"] = first_had_issues
            elif not mrz_data.get("first_name"):
                # –ï—Å–ª–∏ –Ω–µ—Ç –¥–≤–æ–π–Ω—ã—Ö —à–µ–≤—Ä–æ–Ω–æ–≤, –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ –æ–¥–∏–Ω–∞—Ä–Ω—ã–º
                name_parts = name_field.replace("<", " ").split()
                if len(name_parts) > 1:
                    last_name_raw = name_parts[0]
                    first_name_raw = " ".join(name_parts[1:])
                    last_had_issues = self._contains_cyrillic(last_name_raw) or any(c.isdigit() for c in last_name_raw)
                    first_had_issues = self._contains_cyrillic(first_name_raw) or any(c.isdigit() for c in first_name_raw)
                    if self._contains_cyrillic(last_name_raw):
                        last_name_raw = self._transliterate(last_name_raw)
                    if self._contains_cyrillic(first_name_raw):
                        first_name_raw = self._transliterate(first_name_raw)
                    last_name_raw = self._normalize_token(last_name_raw)
                    first_name_raw = self._normalize_token(first_name_raw)
                    mrz_data["last_name"] = last_name_raw
                    mrz_data["first_name"] = first_name_raw
                    mrz_data["last_had_issues"] = last_had_issues
                    mrz_data["first_had_issues"] = first_had_issues

        if len(line2) >= 10:
            doc_field = line2[0:9]
            doc_check = line2[9]
            doc_number = doc_field.replace("<", "")
            if doc_number and re.match(r"^[A-Z0-9]{7,9}$", doc_number):
                if doc_check.isdigit() and self._calculate_mrz_check_digit(doc_field) == int(doc_check):
                    mrz_data["document_number"] = doc_number
                elif doc_number:
                    mrz_data["document_number"] = doc_number

        raw_exp = line2[21:27] if len(line2) >= 27 else ""
        exp_check = line2[27] if len(line2) >= 28 else ""
        exp_date = self._mrz_date_to_iso(raw_exp)
        if exp_date:
            if exp_check.isdigit() and self._calculate_mrz_check_digit(raw_exp) == int(exp_check):
                mrz_data["expiration_date"] = exp_date
            elif not exp_check:
                mrz_data["expiration_date"] = exp_date

        return mrz_data

    def _mrz_date_to_iso(self, raw: str) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã MRZ YYMMDD -> DD.MM.YYYY"""
        if not raw or not raw.isdigit() or len(raw) != 6:
            return ""
        yy = int(raw[0:2])
        mm = int(raw[2:4])
        dd = int(raw[4:6])
        year = 2000 + yy
        current_year = datetime.now().year
        if year < current_year - 20:
            year += 100
        try:
            datetime(year, mm, dd)
            return f"{dd:02d}.{mm:02d}.{year}"
        except ValueError:
            return ""

    def parse_text(self, text: str, mrz_specialized_text: str = "") -> PassportData:
        """–û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ –ø–∞—Å–ø–æ—Ä—Ç–∞

        Args:
            text: –û—Å–Ω–æ–≤–Ω–æ–π OCR —Ç–µ–∫—Å—Ç
            mrz_specialized_text: –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π OCR —Ç–æ–ª—å–∫–æ –¥–ª—è MRZ –∑–æ–Ω—ã
        """
        data = PassportData()

        if self.debug:
            print("\n" + "="*60)
            print("üîç –ù–ê–ß–ê–õ–û –ü–ê–†–°–ò–ù–ì–ê")
            print("="*60)

        # 0. –¢–µ–ª–µ—Ñ–æ–Ω (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –ø–æ–ø–∞–ª –≤ —Å–∫–∞–Ω)
        phone_match = re.search(r'(?:\+7|8)\s?\(?\d{3}\)?\s?\d{3}[\s-]?\d{2}[\s-]?\d{2}', text)
        if phone_match:
            data.phone = phone_match.group(0)

        # 1. –ò–ò–ù (12 —Ü–∏—Ñ—Ä –ø–æ–¥—Ä—è–¥)
        iin_candidates = re.findall(r'\b(\d{12})\b', text)
        chosen_iin = ""
        for cand in iin_candidates:
            if self.validate_iin_checksum(cand):
                chosen_iin = cand
                break
        if not chosen_iin and iin_candidates:
            chosen_iin = iin_candidates[0]  # –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π, –µ—Å–ª–∏ —á–µ–∫-—Å—É–º–º–∞ –Ω–µ –ø—Ä–æ—à–ª–∞

        if chosen_iin:
            data.iin = chosen_iin
            if self.debug:
                print(f"‚úÖ –ò–ò–ù: {data.iin}")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª –∏ –¥–∞—Ç—É —Ä–æ–∂–¥–µ–Ω–∏—è –∏–∑ –ò–ò–ù
            data.gender = self.get_gender_from_iin(data.iin)
            iin_dob = self.extract_date_from_iin(data.iin)
            if iin_dob and not data.dob:
                data.dob = iin_dob
                if self.debug:
                    print(f"‚úÖ –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è –∏–∑ –ò–ò–ù: {data.dob}")

        # 2. –ü–û–õ (–µ—Å–ª–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∏–∑ –ò–ò–ù)
        if not data.gender:
            # –ò—â–µ–º –ø–æ–ª –≤ —Ç–µ–∫—Å—Ç–µ
            gender_patterns = [
                r'(?:–ñ–´–ù–´–°–´|Sex|Gender)[\s:]*([–ú–ñMF–º–∂mf])',
                r'Sex[\s/]*([MF])',
                r'Gender[\s:]*([MF])',
            ]

            for pattern in gender_patterns:
                gender_match = re.search(pattern, text, re.IGNORECASE)
                if gender_match:
                    g = gender_match.group(1).upper()
                    if g in ['M', '–ú']:
                        data.gender = "M"
                    elif g in ['F', '–ñ']:
                        data.gender = "F"
                    if data.gender:
                        if self.debug:
                            print(f"‚úÖ –ü–æ–ª (—Ç–µ–∫—Å—Ç): {data.gender}")
                        break

        # 3. –ù–û–ú–ï–† –î–û–ö–£–ú–ï–ù–¢–ê (N + 8 —Ü–∏—Ñ—Ä)
        doc_patterns = [
            r'(N\d{8})',  # N12345678
            r'‚Ññ[\s]*([N–ê-–Ø0-9]{8,9})',  # ‚Ññ N12345678
            r'–ü–ê–°–ü–û–†–¢[^\n]*?([A-Z0-9]{8,9})',  # –ü–æ—Å–ª–µ —Å–ª–æ–≤–∞ –ü–ê–°–ü–û–†–¢
        ]

        for pattern in doc_patterns:
            doc_match = re.search(pattern, text)
            if doc_match:
                data.document_number = doc_match.group(1).strip()
                if self.debug:
                    print(f"‚úÖ –ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞: {data.document_number}")
                break

        # 4. –§–ê–ú–ò–õ–ò–Ø –ò –ò–ú–Ø
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —á–µ—Ä–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        surname_patterns = [
            r'(?:–¢–ï–ü\s*/?\s*–ó“∞“¢–ê–¢–ú–ï|–¢–ï–ü|–¢–ï–ì–Ü|Surname)[\s:]*\n+([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–ÅA-Z\s]+)',
            r'(?:Last\s*Name)[\s:]*\n+([A-Z\s]+)',
        ]

        raw_last_name = ""
        for pattern in surname_patterns:
            surname_match = re.search(pattern, text, re.IGNORECASE)
            if surname_match:
                raw_last_name = surname_match.group(1).strip()
                # –ü–∞—Ä—Å–∏–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –∏ –≤—ã–±–∏—Ä–∞–µ–º –ª–∞—Ç–∏–Ω–∏—Ü—É –µ—Å–ª–∏ –µ—Å—Ç—å
                lines = raw_last_name.split('\n')
                best_line = None
                best_score = -1
                best_vowels = -1
                for line in lines:
                    clean = line.strip()
                    if not clean or not re.match(r'^[A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å\s]+$', clean):
                        continue
                    latin_count = sum(1 for c in clean if 'A' <= c.upper() <= 'Z')
                    cyr_count = sum(1 for c in clean if '–ê' <= c.upper() <= '–Ø' or c in "–Å”ò”®“Æ“∞“í“ö“¢“∫–Ü")
                    vowel_count = sum(1 for c in clean if c.upper() in "AEIOUY")
                    score = latin_count * 2 - cyr_count
                    if (
                        score > best_score
                        or (score == best_score and vowel_count > best_vowels)
                        or (score == best_score and vowel_count == best_vowels)
                    ):
                        best_score = score
                        best_vowels = vowel_count
                        best_line = clean

                if best_line:
                    normalized = self._normalize_token(best_line)
                    data.last_name = normalized or best_line
                    if self.debug:
                        print(f"‚úÖ –§–∞–º–∏–ª–∏—è: {data.last_name}")
                break

        # –ò–º—è
        name_patterns = [
            r'(?:–ê–¢–´|Given\s*names?|First\s*Names?)[\s:]*\n+([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å\s\n]+)',
            r'GIVEN\s*NAMES?[\s:]*\n+([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å\s\n]+)',
            r'–ê–¢–´[^\n]*\n+([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å\s\n]+)',
        ]

        for pattern in name_patterns:
            name_match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
            if name_match:
                name_text = name_match.group(1).strip()
                lines = [ln.strip() for ln in name_text.split('\n') if ln.strip()]
                if lines:
                    best_line = max(lines, key=lambda l: sum(1 for c in l if 'A' <= c.upper() <= 'Z'))
                    cleaned = self._normalize_token(best_line)
                    if cleaned and len(cleaned) > 2 and "PASSPORT" not in cleaned.upper():
                        parts = cleaned.split()
                        if len(parts) > 1 and len(parts[0]) <= 3 and len(parts[1]) > 3:
                            cleaned = parts[1]  # –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–π –ø—Ä–µ—Ñ–∏–∫—Å –≤—Ä–æ–¥–µ ZH
                        data.first_name = cleaned
                        if self.debug:
                            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∏–º—è: {data.first_name}")
                        break

        # –î–æ–ø. —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ –∏–º—è –≤—Å–µ –µ—â—ë –ø—É—Å—Ç–æ–µ, –±–µ—Ä–µ–º –ª–∞—Ç–∏–Ω–∏—Ü—É –∏–∑ —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å–ª–æ–≤
        if not data.first_name:
            lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
            latin_lines = []
            for ln in lines:
                cleaned = self._normalize_token(ln)
                if not cleaned or len(cleaned) < 2 or len(cleaned) > 30:
                    continue
                up = cleaned.upper()
                if any(x in up for x in ["PASSPORT", "KAZ", "NATIONALITY", "MINISTRY"]):
                    continue
                if up == (data.last_name or "").upper():
                    continue
                latin_lines.append(cleaned)
            if latin_lines:
                data.first_name = latin_lines[0]
                if self.debug:
                    print(f"‚úÖ –ò–º—è –ø–æ –ª–∞—Ç–∏–Ω–∏—Ü–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞: {data.first_name}")

        # –î–æ–ø. fallback –¥–ª—è —Ñ–∞–º–∏–ª–∏–∏: –∏—â–µ–º –ª—é–±—É—é –ø–æ–¥—Ö–æ–¥—è—â—É—é —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ –µ—â—ë –ø—É—Å—Ç–æ
        if not data.last_name:
            for ln in text.splitlines():
                cleaned = self._normalize_token(ln)
                if not cleaned or len(cleaned) < 4 or len(cleaned) > 25:
                    continue
                up = cleaned.upper()
                if any(x in up for x in ["PASSPORT", "KAZ", "NATIONALITY", "MINISTRY", "GIVEN", "SURNAME"]):
                    continue
                if data.first_name and up == data.first_name.upper():
                    continue
                parts = cleaned.split()
                if len(parts) > 1 and len(parts[-1]) <= 2:
                    cleaned = " ".join(parts[:-1])
                data.last_name = cleaned
                if self.debug:
                    print(f"‚úÖ –§–∞–º–∏–ª–∏—è (fallback): {data.last_name}")
                break

        # –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–æ–ø–∞–ª–∏ –ª–∏ –æ–±–∞ –∏–º–µ–Ω–∏ –≤ –æ–¥–Ω–æ –ø–æ–ª–µ
        if data.last_name and not data.first_name:
            # –ï—Å–ª–∏ –≤ —Ñ–∞–º–∏–ª–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤, –≤–æ–∑–º–æ–∂–Ω–æ —Ç–∞–º –∏ –∏–º—è —Ç–æ–∂–µ
            if len(data.last_name.split()) > 1:
                if self.debug:
                    print(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≤ —Ñ–∞–º–∏–ª–∏–∏: {data.last_name}")
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —É–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
                split_last, split_first = self._smart_name_split(data.last_name)
                if split_first:  # –ï—Å–ª–∏ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å
                    data.last_name = split_last
                    data.first_name = split_first
                    if self.debug:
                        print(f"‚úÖ –ü–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è - –§–∞–º–∏–ª–∏—è: {data.last_name}, –ò–º—è: {data.first_name}")

        elif data.first_name and not data.last_name:
            # –ï—Å–ª–∏ –∏–º—è –µ—Å—Ç—å, –∞ —Ñ–∞–º–∏–ª–∏–∏ –Ω–µ—Ç - –≤–æ–∑–º–æ–∂–Ω–æ –≤—Å–µ –≤ –∏–º–µ–Ω–∏
            if len(data.first_name.split()) > 1:
                if self.debug:
                    print(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≤ –∏–º–µ–Ω–∏: {data.first_name}")
                split_last, split_first = self._smart_name_split(data.first_name)
                data.last_name = split_last
                data.first_name = split_first
                if self.debug:
                    print(f"‚úÖ –ü–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è - –§–∞–º–∏–ª–∏—è: {data.last_name}, –ò–º—è: {data.first_name}")

        # 5. –î–ê–¢–´
        # –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è
        if not data.dob:
            dob_patterns = [
                r'(?:–¢–£“í–ê–ù\s*–ö“Æ–ù–Ü|Date\s*of\s*birth|–î–∞—Ç–∞\s*—Ä–æ–∂–¥–µ–Ω–∏—è)[\s:]*(\d{2}[./]\d{2}[./]\d{4})',
                r'(?:Born|–†–æ–¥–∏–ª—Å—è)[\s:]*(\d{2}[./]\d{2}[./]\d{4})',
                r'(\d{2}\.\d{2}\.\d{4})',  # –ü—Ä–æ—Å—Ç–æ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã
            ]

            for pattern in dob_patterns:
                dob_match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
                if dob_match:
                    data.dob = dob_match.group(1).replace('/', '.')
                    if self.debug:
                        print(f"‚úÖ –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è: {data.dob}")
                    break

        # –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è
        exp_patterns = [
            r'(?:–ú–ï–†–ó–Ü–ú(?:–Ü)?|–ñ–ê–†–ê–ú–î–´\s*–î–û|Expiry|Expires|Valid\s*(?:until|to)|Date\s*of\s*Expiry|–î–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω\s*–¥–æ)[^\d]*(\d{2}\s*[./-]\s*\d{2}\s*[./-]\s*\d{4})',
            r'(?:Valid\s*until)[\s:]*(\d{2}\s*[./-]\s*\d{2}\s*[./-]\s*\d{4})',
            r'(?:–¥–æ\s*)(\d{2}\s*[./-]\s*\d{2}\s*[./-]\s*\d{4})',
        ]

        for pattern in exp_patterns:
            exp_match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if exp_match:
                data.expiration_date = self._clean_date(exp_match.group(1))
                if self.debug:
                    print(f"‚úÖ –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è: {data.expiration_date}")
                break

        # 6. MRZ OVERRIDE (—Å–∞–º—ã–π —Ç–æ—á–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–º–µ–Ω –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏)
        mrz_data = self.parse_mrz(text, mrz_specialized_text)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º MRZ –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π (—Ç–µ–ø–µ—Ä—å —Ç–∞–º –≤—Å–µ–≥–¥–∞ –ª–∞—Ç–∏–Ω–∏—Ü–∞ –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏)
        use_mrz = False
        if mrz_data.get("last_name"):
            mrz_last = mrz_data["last_name"]
            mrz_first = mrz_data.get("first_name", "")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Å–ª–æ–≤–∞—Ä—è (—á—Ç–æ–±—ã —Ñ—Ä–æ–Ω—Ç –±—Ä–∞–ª –ª–∞—Ç–∏–Ω–∏—Ü—É)
            data.mrz_last_name = mrz_last
            data.mrz_first_name = mrz_first

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ MRZ: –µ—Å—Ç—å –ª–∏ –≤ –Ω–µ–º —Ö–æ—Ç—è –±—ã 2 –±—É–∫–≤—ã
            if len(mrz_last) >= 2 and mrz_last.replace(" ", "").isalpha():
                use_mrz = True

                # –ï—Å–ª–∏ MRZ –µ—Å—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–º–µ–Ω
                if mrz_last and not mrz_first and len(mrz_last.split()) > 1:
                    if self.debug:
                        print(f"‚ö†Ô∏è MRZ: –ù–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≤ —Ñ–∞–º–∏–ª–∏–∏: {mrz_last}")
                    split_last, split_first = self._smart_name_split(mrz_last)
                    data.last_name = split_last
                    data.first_name = split_first
                    if self.debug:
                        print(f"‚úÖ MRZ –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è - –§–∞–º–∏–ª–∏—è: {data.last_name}, –ò–º—è: {data.first_name}")
                else:
                    # –†–µ—à–∞–µ–º, —á–µ–º –∑–∞–º–µ–Ω–∏—Ç—å: MRZ –∏–ª–∏ —Ç–µ–∫—Å—Ç, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å –≤–µ—Ä–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∏–º–µ–Ω–∞
                    def should_replace(text_val: str, mrz_val: str, mrz_had_issues: bool = False) -> bool:
                        if not mrz_val:
                            return False
                        mrz_q = self._name_quality(mrz_val)
                        text_q = self._name_quality(text_val)
                        similar = self._are_similar_words(mrz_val.replace(" ", ""), (text_val or "").replace(" ", ""))

                        if not text_val:
                            return True
                        if self._contains_cyrillic(text_val):
                            return True
                        if self._looks_like_noise_name(text_val):
                            return True

                        # –ö–õ–Æ–ß–ï–í–û–ï –ü–†–ê–í–ò–õ–û 1: –ï—Å–ª–∏ MRZ –ë–ï–ó –æ—à–∏–±–æ–∫ (—á–∏—Å—Ç–∞—è –ª–∞—Ç–∏–Ω–∏—Ü–∞) - –û–ë–´–ß–ù–û –∏—Å–ø–æ–ª—å–∑—É–µ–º MRZ!
                        # –ù–û –ø—Ä–æ–≤–µ—Ä—è–µ–º: –≤–æ–∑–º–æ–∂–Ω–æ —Ç–µ–∫—Å—Ç —ç—Ç–æ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∞—è –∏ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è
                        if not mrz_had_issues:
                            if mrz_q >= 4:  # MRZ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π (–º–∏–Ω–∏–º—É–º 4 –±—É–∫–≤—ã)
                                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—á–µ MRZ –∏ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂,
                                # –≤–æ–∑–º–æ–∂–Ω–æ –≤ MRZ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã (–æ—à–∏–±–∫–∞ OCR)
                                if text_q >= 4 and len(text_val) < len(mrz_val):
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º: MRZ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç –∫–∞–∫ –ø–æ–¥—Å—Ç—Ä–æ–∫—É (—Å –Ω–µ–±–æ–ª—å—à–∏–º–∏ –æ—Ç–ª–∏—á–∏—è–º–∏)
                                    mrz_clean = mrz_val.replace(" ", "").upper()
                                    text_clean = text_val.replace(" ", "").upper()

                                    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —è–≤–ª—è–µ—Ç—Å—è —á–∞—Å—Ç—å—é MRZ –∏–ª–∏ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂ (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ <= 1)
                                    if text_clean in mrz_clean or self._levenshtein_distance(text_clean, mrz_clean) == 1:
                                        if self.debug:
                                            print(f"   ‚ö†Ô∏è  MRZ —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã, —Ç–µ–∫—Å—Ç —Ç–æ—á–Ω–µ–µ: {text_val}")
                                        return False

                                if self.debug:
                                    print(f"   ‚úÖ MRZ —á–∏—Å—Ç—ã–π (–±–µ–∑ –æ—à–∏–±–æ–∫ OCR), –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ: {mrz_val}")
                                return True

                        # –ö–õ–Æ–ß–ï–í–û–ï –ü–†–ê–í–ò–õ–û 2: –ï—Å–ª–∏ MRZ –±—ã–ª —Å –æ—à–∏–±–∫–∞–º–∏ OCR (–∫–∏—Ä–∏–ª–ª–∏—Ü–∞/—Ü–∏—Ñ—Ä—ã),
                        # –∞ —Ç–µ–∫—Å—Ç —á–∏—Å—Ç—ã–π –ª–∞—Ç–∏–Ω—Å–∫–∏–π –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π - –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç
                        if mrz_had_issues and text_q >= 4:  # –º–∏–Ω–∏–º—É–º 4 –±—É–∫–≤—ã –≤ —Ç–µ–∫—Å—Ç–µ
                            if self.debug:
                                print(f"   ‚ö†Ô∏è  MRZ –±—ã–ª —Å –æ—à–∏–±–∫–∞–º–∏ OCR, –∏—Å–ø–æ–ª—å–∑—É–µ–º —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç: {text_val}")
                            return False

                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ —Å–ª–æ–≤–∞ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏ –∏ MRZ –Ω–µ–º–Ω–æ–≥–æ –ª—É—á—à–µ
                        if similar and mrz_q > text_q:
                            if self.debug:
                                print(f"   ‚ÑπÔ∏è  –°–ª–æ–≤–∞ –ø–æ—Ö–æ–∂–∏, –Ω–æ MRZ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–µ–µ: {mrz_val}")
                            return True

                        # –ï—Å–ª–∏ –Ω–µ –ø–æ—Ö–æ–∂–∏, —Ç—Ä–µ–±—É–µ–º –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ MRZ
                        if not similar and mrz_q >= text_q + 2:
                            return True

                        return False

                    mrz_last_had_issues = mrz_data.get("last_had_issues", False)
                    mrz_first_had_issues = mrz_data.get("first_had_issues", False)

                    if should_replace(data.last_name, mrz_last, mrz_last_had_issues):
                        data.last_name = mrz_last
                        if self.debug:
                            print(f"‚úÖ –§–∞–º–∏–ª–∏—è (MRZ): {data.last_name}")
                    else:
                        if self.debug and data.last_name:
                            print(f"‚úÖ –§–∞–º–∏–ª–∏—è (—Ç–µ–∫—Å—Ç): {data.last_name}")

                    if should_replace(data.first_name, mrz_first, mrz_first_had_issues):
                        data.first_name = mrz_first
                        if self.debug:
                            print(f"‚úÖ –ò–º—è (MRZ): {data.first_name}")
                    else:
                        if self.debug and data.first_name:
                            print(f"‚úÖ –ò–º—è (—Ç–µ–∫—Å—Ç): {data.first_name}")
            else:
                if self.debug:
                    print(f"‚ö†Ô∏è MRZ —Ñ–∞–º–∏–ª–∏—è –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è: '{mrz_last}'")

        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è –≤—Å—ë –µ—â—ë –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ ‚Äî —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º
        if self._contains_cyrillic(data.last_name):
            old_last = data.last_name
            data.last_name = self._transliterate(data.last_name)
            if self.debug:
                print(f"üîÑ –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è —Ñ–∞–º–∏–ª–∏–∏: {old_last} ‚Üí {data.last_name}")

        if self._contains_cyrillic(data.first_name):
            old_first = data.first_name
            data.first_name = self._transliterate(data.first_name)
            if self.debug:
                print(f"üîÑ –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏: {old_first} ‚Üí {data.first_name}")

        # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞/–º—É—Å–æ—Ä –ø–æ—Å–ª–µ –≤—Å–µ—Ö –∑–∞–º–µ–Ω
        data.last_name = self._remove_noise_tokens(data.last_name)
        data.first_name = self._remove_noise_tokens(data.first_name)

        if mrz_data.get("document_number"):
            data.document_number = mrz_data["document_number"]
            if self.debug:
                print(f"‚úÖ –ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ (MRZ): {data.document_number}")
        if mrz_data.get("expiration_date"):
            data.expiration_date = mrz_data["expiration_date"]
            if self.debug:
                print(f"‚úÖ –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è (MRZ): {data.expiration_date}")

        if not data.expiration_date:
            generic_matches = re.findall(r'(\d{2}(?:\s*[./-]\s*|\s+)\d{2}(?:\s*[./-]\s*|\s+)\d{4})', text)
            for match in reversed(generic_matches):
                cleaned = self._clean_date(match)
                if cleaned and cleaned != data.dob:
                    data.expiration_date = cleaned
                    if self.debug:
                        print(f"‚úÖ –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è (fallback): {data.expiration_date}")
                    break

        if self.debug:
            print("="*60)
            print(f"üìä –ò–¢–û–ì–û–í–´–ï –î–ê–ù–ù–´–ï:")
            print(f"   –§–∞–º–∏–ª–∏—è: {data.last_name}")
            print(f"   –ò–º—è: {data.first_name}")
            print(f"   –ü–æ–ª: {data.gender}")
            print(f"   –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è: {data.dob}")
            print(f"   –ò–ò–ù: {data.iin}")
            print(f"   –î–æ–∫—É–º–µ–Ω—Ç: {data.document_number}")
            print(f"   –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è: {data.expiration_date}")
            print(f"   –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å: {data.is_valid}")
            print("="*60 + "\n")

        return data

    def parse(self, file_path: str) -> PassportData:
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ñ–∞–π–ª–∞"""
        text, mrz_text = self.extract_ocr_text(file_path)
        return self.parse_text(text, mrz_text)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
def test_parser(file_path: str):
    parser = PassportParser(debug=True)
    result = parser.parse(file_path)
    print("\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢:")
    print(result.to_dict())
    return result
