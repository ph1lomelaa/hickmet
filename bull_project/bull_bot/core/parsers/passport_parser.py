import cv2
import pytesseract
import numpy as np
from pdf2image import convert_from_path
from PIL import Image
import os
import re
from dataclasses import dataclass
from datetime import datetime

@dataclass
class PassportData:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ø–∞—Å–ø–æ—Ä—Ç–∞"""
    last_name: str = ""
    first_name: str = ""
    gender: str = ""
    dob: str = ""
    iin: str = ""
    document_number: str = ""
    expiration_date: str = ""
    phone: str = ""  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–∞

    @property
    def full_name(self) -> str:
        return f"{self.last_name} {self.first_name}".strip()

    @property
    def is_valid(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö"""
        has_name = bool(self.last_name or self.first_name)
        has_iin = len(self.iin) == 12 if self.iin else False
        has_doc = bool(self.document_number)
        # –°—á–∏—Ç–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–º –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –∏–º—è –ò (–ò–ò–ù –ò–õ–ò –¥–æ–∫—É–º–µ–Ω—Ç)
        return has_name and (has_iin or has_doc)

    def to_dict(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è API"""
        return {
            "last_name": self.last_name or "-",
            "first_name": self.first_name or "-",
            "gender": self.gender or "M",
            "date_of_birth": self.dob or "-",
            "passport_num": self.document_number or "-",
            "phone": self.phone or "-",
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            "Last Name": self.last_name or "-",
            "First Name": self.first_name or "-",
            "Gender": self.gender or "M",
            "Date of Birth": self.dob or "-",
            "Document Number": self.document_number or "-",
            "Document Expiration": self.expiration_date or "-",
            "IIN": self.iin or "-",
            "MRZ_LAST": getattr(self, "mrz_last_name", None),
            "MRZ_FIRST": getattr(self, "mrz_first_name", None),
        }

class PassportParser:
    def __init__(self, poppler_path: str = None, debug: bool = False, save_ocr: bool = False):
        self.poppler_path = poppler_path
        self.debug = debug
        self.save_ocr = save_ocr  # –ù–æ–≤–∞—è –æ–ø—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è OCR —Ç–µ–∫—Å—Ç–∞
        self._date_cleaner = re.compile(r"\s+")
        self._digit_map = {"0": "O", "1": "I", "2": "Z", "3": "Z", "4": "A", "5": "S", "6": "G", "7": "T", "8": "B", "9": "P"}
        self._cyr_map = {
            "–ê": "A", "–ë": "B", "–í": "V", "–ì": "G", "–î": "D", "–ï": "E", "–Å": "E",
            "–ñ": "ZH", "–ó": "Z", "–ò": "I", "–ô": "Y", "–ö": "K", "–õ": "L", "–ú": "M",
            "–ù": "N", "–û": "O", "–ü": "P", "–†": "R", "–°": "S", "–¢": "T", "–£": "U",
            "–§": "F", "–•": "KH", "–¶": "TS", "–ß": "CH", "–®": "SH", "–©": "SCH",
            "–™": "", "–´": "Y", "–¨": "", "–≠": "E", "–Æ": "YU", "–Ø": "YA",
            "“ö": "K", "”ò": "A", "“¢": "N", "“í": "G", "“Æ": "U", "“∞": "U", "”®": "O", "“∫": "H", "–Ü": "I", "—ñ": "I",
            "–∞": "A", "–±": "B", "–≤": "V", "–≥": "G", "–¥": "D", "–µ": "E", "—ë": "E",
            "–∂": "ZH", "–∑": "Z", "–∏": "I", "–π": "Y", "–∫": "K", "–ª": "L", "–º": "M",
            "–Ω": "N", "–æ": "O", "–ø": "P", "—Ä": "R", "—Å": "S", "—Ç": "T", "—É": "U",
            "—Ñ": "F", "—Ö": "KH", "—Ü": "TS", "—á": "CH", "—à": "SH", "—â": "SCH",
            "—ä": "", "—ã": "Y", "—å": "", "—ç": "E", "—é": "YU", "—è": "YA",
            "“õ": "K", "”ô": "A", "“£": "N", "“ì": "G", "“Ø": "U", "“±": "U", "”©": "O", "“ª": "H",
        }

    def validate_iin_checksum(self, iin: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º—ã –ò–ò–ù –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞."""
        if not iin or len(iin) != 12 or not iin.isdigit():
            return False

        weights1 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
        checksum = sum(int(iin[i]) * weights1[i] for i in range(11)) % 11

        if checksum == 10:
            weights2 = [3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2]
            checksum = sum(int(iin[i]) * weights2[i] for i in range(11)) % 11

        return checksum == int(iin[11])

    def _calculate_mrz_check_digit(self, data: str) -> int:
        """–†–∞—Å—á–µ—Ç –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ü–∏—Ñ—Ä—ã MRZ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç ICAO)."""
        weights = [7, 3, 1]
        total = 0
        for i, char in enumerate(data):
            if char == '<':
                val = 0
            elif '0' <= char <= '9':
                val = ord(char) - ord('0')
            elif 'A' <= char <= 'Z':
                val = ord(char) - ord('A') + 10
            else:
                val = 0
            total += val * weights[i % 3]
        return total % 10

    def _clean_date(self, value: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏."""
        if not value:
            return ""
        stripped = self._date_cleaner.sub("", value)
        stripped = stripped.replace('/', '.').replace('-', '.')
        if len(stripped) == 8 and stripped.isdigit():
            return f"{stripped[0:2]}.{stripped[2:4]}.{stripped[4:]}"
        return stripped

    def _contains_cyrillic(self, value: str) -> bool:
        return any("–ê" <= c <= "—è" or c in "–Å—ë“ö“õ”ò”ô“¢“£“í“ì“Æ“Ø“∞“±”®”©“∫“ª" for c in value or "")

    def _transliterate(self, value: str) -> str:
        if not value:
            return ""
        return "".join(self._cyr_map.get(ch, ch) for ch in value)

    def _normalize_token(self, value: str) -> str:
        """
        –ü—Ä–∏–≤–æ–¥–∏—Ç –∏–º—è/—Ñ–∞–º–∏–ª–∏—é –∫ –ª–∞—Ç–∏–Ω–∏—Ü–µ, —É–±–∏—Ä–∞–µ—Ç —à—É–º –∏ OCR-—Ü–∏—Ñ—Ä—ã.
        """
        if not value:
            return ""
        # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
        value = self._transliterate(value)
        # –ó–∞–º–µ–Ω—è–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ü–∏—Ñ—Ä—ã –Ω–∞ –±—É–∫–≤—ã
        value = "".join(self._digit_map.get(ch, ch) for ch in value)
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω–∏—Ü—É –∏ –ø—Ä–æ–±–µ–ª—ã
        value = re.sub(r"[^A-Z\s]", "", value.upper())
        return value.strip()

    def preprocess_image(self, image: Image.Image) -> np.ndarray:
        """–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        img = np.array(image)
        if len(img.shape) == 3:
            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # CLAHE –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

        return binary

    def extract_ocr_text(self, file_path: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Tesseract"""
        try:
            if file_path.lower().endswith('.pdf'):
                pages = convert_from_path(file_path, dpi=300, poppler_path=self.poppler_path)
                if not pages:
                    return ""
                pil_image = pages[0]
            else:
                pil_image = Image.open(file_path)

            processed_img = self.preprocess_image(pil_image)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —è–∑—ã–∫–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            text = pytesseract.image_to_string(
                processed_img,
                lang="kaz+rus+eng",
                config='--psm 6'  # Assume uniform block of text
            )

            # –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º OCR —Ç–µ–∫—Å—Ç –≤ —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            if self.save_ocr or self.debug:
                ocr_file = file_path + ".ocr_text.txt"
                with open(ocr_file, "w", encoding="utf-8") as f:
                    f.write(text)
                print(f"üíæ OCR —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {ocr_file}")

            if self.debug:
                print("üìÑ OCR TEXT START" + "="*40)
                print(text)
                print("="*40 + " OCR TEXT END")

            return text
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ OCR: {e}")
            return ""

    def get_gender_from_iin(self, iin: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∞ –ø–æ 7-–π —Ü–∏—Ñ—Ä–µ –ò–ò–ù"""
        if not iin or len(iin) != 12 or not iin.isdigit():
            return ""
        digit = int(iin[6])
        return "M" if digit in [1, 3, 5] else "F" if digit in [2, 4, 6] else ""

    def extract_date_from_iin(self, iin: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç—ã —Ä–æ–∂–¥–µ–Ω–∏—è –∏–∑ –ò–ò–ù (–ø–µ—Ä–≤—ã–µ 6 —Ü–∏—Ñ—Ä - YYMMDD)"""
        if not iin or len(iin) < 6 or not iin[:6].isdigit():
            return ""

        try:
            yy = int(iin[0:2])
            mm = int(iin[2:4])
            dd = int(iin[4:6])

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–µ–∫ –ø–æ 7-–π —Ü–∏—Ñ—Ä–µ
            century_digit = int(iin[6]) if len(iin) > 6 else 0
            if century_digit in [1, 2]:
                year = 1800 + yy
            elif century_digit in [3, 4]:
                year = 1900 + yy
            elif century_digit in [5, 6]:
                year = 2000 + yy
            else:
                year = 1900 + yy  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 1900-–µ

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –¥–∞—Ç—ã
            datetime(year, mm, dd)

            return f"{dd:02d}.{mm:02d}.{year}"
        except (ValueError, IndexError):
            return ""

    def _levenshtein_distance(self, s1: str, s2: str) -> int:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞ –º–µ–∂–¥—É –¥–≤—É–º—è —Å—Ç—Ä–æ–∫–∞–º–∏"""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)

        if len(s2) == 0:
            return len(s1)

        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row

        return previous_row[-1]

    def _are_similar_words(self, word1: str, word2: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ—Ö–æ–∂–∏ –ª–∏ –¥–≤–∞ —Å–ª–æ–≤–∞ (–≤–æ–∑–º–æ–∂–Ω–æ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç - –æ—à–∏–±–∫–∞ OCR)"""
        if not word1 or not word2:
            return False

        w1, w2 = word1.upper(), word2.upper()
        if w1 == w2:
            return True

        # –°–ª–æ–≤–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–Ω–æ–π –¥–ª–∏–Ω—ã
        if abs(len(w1) - len(w2)) > 3:
            return False

        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞
        distance = self._levenshtein_distance(w1, w2)
        max_len = max(len(w1), len(w2))

        # –ï—Å–ª–∏ —Å–ª–æ–≤–∞ –ø–æ—Ö–æ–∂–∏ –Ω–∞ 60% –∏ –±–æ–ª–µ–µ - —Å—á–∏—Ç–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏
        similarity = 1 - (distance / max_len)
        if similarity >= 0.6:
            return True

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è –ø–æ—Ö–æ–∂–µ –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—Ç—Å—è –ø–æ—Ö–æ–∂–µ
        if len(w1) >= 4 and len(w2) >= 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ö–æ—Ç—è –±—ã 3 –∏–∑ –ø–µ—Ä–≤—ã—Ö 4 –±—É–∫–≤ —Å–æ–≤–ø–∞–¥–∞—é—Ç
            matches = sum(1 for i in range(min(4, len(w1), len(w2))) if i < len(w1) and i < len(w2) and w1[i] == w2[i])
            if matches >= 3:
                return True

        return False

    def _remove_similar_duplicates(self, parts: list) -> list:
        """–£–¥–∞–ª—è–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤ (–æ—Å—Ç–∞–≤–ª—è–µ—Ç –±–æ–ª–µ–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç)"""
        if len(parts) <= 1:
            return parts

        cleaned = []
        skip_indices = set()

        for i, word in enumerate(parts):
            if i in skip_indices:
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–æ—Ö–æ–∂–µ–µ —Å–ª–æ–≤–æ –¥–∞–ª—å—à–µ
            found_similar = False
            for j in range(i + 1, len(parts)):
                if j in skip_indices:
                    continue

                if self._are_similar_words(word, parts[j]):
                    # –ù–∞—à–ª–∏ –ø–æ—Ö–æ–∂–µ–µ —Å–ª–æ–≤–æ - –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–µ–µ
                    # –ö—Ä–∏—Ç–µ—Ä–∏–π: —Å–ª–æ–≤–æ —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–≥–ª–∞–≤–Ω—ã—Ö –ª–∞—Ç–∏–Ω—Å–∫–∏—Ö –±—É–∫–≤
                    word_latin_count = sum(1 for c in word if c.isupper() and c.isalpha() and ord('A') <= ord(c) <= ord('Z'))
                    other_latin_count = sum(1 for c in parts[j] if c.isupper() and c.isalpha() and ord('A') <= ord(c) <= ord('Z'))

                    if other_latin_count > word_latin_count:
                        # –î—Ä—É–≥–æ–µ —Å–ª–æ–≤–æ –ª—É—á—à–µ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ–∫—É—â–µ–µ
                        skip_indices.add(i)
                        found_similar = True
                        break
                    else:
                        # –¢–µ–∫—É—â–µ–µ —Å–ª–æ–≤–æ –ª—É—á—à–µ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—Ä—É–≥–æ–µ
                        skip_indices.add(j)

            if not found_similar:
                cleaned.append(word)

        return cleaned

    def _smart_name_split(self, name_string: str) -> tuple:
        """–£–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∏–º–µ–Ω–∏ –Ω–∞ —Ñ–∞–º–∏–ª–∏—é –∏ –∏–º—è"""
        if not name_string:
            return ("", "")

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º
        parts = name_string.strip().split()

        if len(parts) == 0:
            return ("", "")

        # –£–¥–∞–ª—è–µ–º –ø–æ—Ö–æ–∂–∏–µ –¥—É–±–ª–∏–∫–∞—Ç—ã (OCR —á–∞—Å—Ç–æ –≤–∏–¥–∏—Ç –æ–¥–Ω–æ —Å–ª–æ–≤–æ –¥–≤–∞–∂–¥—ã)
        parts = self._remove_similar_duplicates(parts)

        if len(parts) == 0:
            return ("", "")
        elif len(parts) == 1:
            # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —Å–ª–æ–≤–æ - —Å—á–∏—Ç–∞–µ–º —Ñ–∞–º–∏–ª–∏–µ–π
            return (parts[0], "")
        else:
            # –ü–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ - —Ñ–∞–º–∏–ª–∏—è, –æ—Å—Ç–∞–ª—å–Ω—ã–µ - –∏–º—è
            last_name = parts[0]
            first_name = " ".join(parts[1:])
            return (last_name, first_name)

    def parse_mrz(self, text: str) -> dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ MRZ (Machine Readable Zone) - —Å—Ç—Ä–æ–∫–∞ –≤–Ω–∏–∑—É –ø–∞—Å–ø–æ—Ä—Ç–∞"""
        mrz_data = {}
        raw_lines = [line.strip().replace(" ", "") for line in text.splitlines()]
        # –†–∞—Å—à–∏—Ä—è–µ–º –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –≤ MRZ
        mrz_lines = [re.sub(r'[^A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9<]', '', line, flags=re.IGNORECASE) for line in raw_lines if len(re.sub(r'[^A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å0-9<]', '', line, flags=re.IGNORECASE)) >= 25]

        if len(mrz_lines) < 2:
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω —Å —à–µ–≤—Ä–æ–Ω–∞–º–∏ (OCR –º–æ–∂–µ—Ç –≤–∏–¥–µ—Ç—å << –∫–∞–∫ < <, \< < –∏ —Ç.–¥.)
            patterns = [
                r'([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å]{3,})\s*<<\s*([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å]{3,})',  # —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π <<
                r'([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å]{3,})\s*<\s*<\s*([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å]{3,})',  # < <
                r'([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å]{3,})\\<\s*<\s*([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å]{3,})',  # \< <
                r'([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å]{3,})<\s+<\s*([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å]{3,})',  # < <
            ]

            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    last_name = match.group(1).replace("<", "").replace("\\", "").strip()
                    first_name = match.group(2).replace("<", "").replace("\\", "").strip()

                    if self.debug:
                        print(f"  üìç –ù–∞–π–¥–µ–Ω MRZ –ø–∞—Ç—Ç–µ—Ä–Ω:")
                        print(f"     –ò—Å—Ö–æ–¥–Ω–∞—è —Ñ–∞–º–∏–ª–∏—è: '{last_name}'")
                        print(f"     –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–º—è:     '{first_name}'")

                    # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º –µ—Å–ª–∏ –∫–∏—Ä–∏–ª–ª–∏—Ü–∞
                    if self._contains_cyrillic(last_name):
                        if self.debug:
                            print(f"     ‚ö†Ô∏è  –§–∞–º–∏–ª–∏—è –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ, —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º...")
                        last_name = self._transliterate(last_name)
                    last_name = self._normalize_token(last_name)
                    if self.debug:
                        print(f"     ‚úÖ –ü–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏: '{last_name}'")

                    if self._contains_cyrillic(first_name):
                        if self.debug:
                            print(f"     ‚ö†Ô∏è  –ò–º—è –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ, —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º...")
                        first_name = self._transliterate(first_name)
                    first_name = self._normalize_token(first_name)
                    if self.debug:
                        print(f"     ‚úÖ –ü–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏: '{first_name}'")

                    mrz_data["last_name"] = last_name
                    mrz_data["first_name"] = first_name
                    if self.debug:
                        print(f"‚úÖ MRZ (pattern): {mrz_data['last_name']} {mrz_data.get('first_name', '')}")
                    return mrz_data

            return mrz_data

        line1, line2 = mrz_lines[-2], mrz_lines[-1]
        if self.debug:
            print(f"‚úÖ MRZ —Å—Ç—Ä–æ–∫–∞ 1 (raw): {line1}")
            print(f"‚úÖ MRZ —Å—Ç—Ä–æ–∫–∞ 2 (raw): {line2}")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç MRZ
        if line1.startswith("P<"):
            # –§–æ—Ä–º–∞—Ç: P<XXX –≥–¥–µ XXX = –∫–æ–¥ —Å—Ç—Ä–∞–Ω—ã (3 –±—É–∫–≤—ã)
            # –ü–æ—Å–ª–µ –∫–æ–¥–∞ —Å—Ç—Ä–∞–Ω—ã –∏–¥–µ—Ç —Ñ–∞–º–∏–ª–∏—è
            if len(line1) > 5:
                # P< + 3 –±—É–∫–≤—ã –∫–æ–¥–∞ = 5 —Å–∏–º–≤–æ–ª–æ–≤
                name_field = line1[5:]
            else:
                name_field = line1[2:]  # Fallback: –ø—Ä–æ—Å—Ç–æ —É–±–∏—Ä–∞–µ–º P<
        else:
            name_field = line1

        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –¥–≤–æ–π–Ω—ã–º —à–µ–≤—Ä–æ–Ω–∞–º
        name_part = name_field.split("<<", 1)
        if name_part:
            last_name_raw = name_part[0].replace("<", "")
            # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º –µ—Å–ª–∏ –∫–∏—Ä–∏–ª–ª–∏—Ü–∞
            if self._contains_cyrillic(last_name_raw):
                if self.debug:
                    print(f"‚ö†Ô∏è MRZ —Ñ–∞–º–∏–ª–∏—è –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ: {last_name_raw}")
            last_name_raw = self._transliterate(last_name_raw)
            last_name_raw = self._normalize_token(last_name_raw)
            if self.debug:
                print(f"‚úÖ –ü–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏: {last_name_raw}")
            mrz_data["last_name"] = last_name_raw

            if len(name_part) > 1:
                # –£–±–∏—Ä–∞–µ–º –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ —à–µ–≤—Ä–æ–Ω—ã –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
                first_name_raw = name_part[1].replace("<", " ").strip()
                if self._contains_cyrillic(first_name_raw):
                    if self.debug:
                        print(f"‚ö†Ô∏è MRZ –∏–º—è –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ: {first_name_raw}")
                first_name_raw = self._transliterate(first_name_raw)
                first_name_raw = self._normalize_token(first_name_raw)
                if self.debug:
                    print(f"‚úÖ –ü–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏: {first_name_raw}")
                mrz_data["first_name"] = first_name_raw
            elif not mrz_data.get("first_name"):
                # –ï—Å–ª–∏ –Ω–µ—Ç –¥–≤–æ–π–Ω—ã—Ö —à–µ–≤—Ä–æ–Ω–æ–≤, –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ –æ–¥–∏–Ω–∞—Ä–Ω—ã–º
                name_parts = name_field.replace("<", " ").split()
                if len(name_parts) > 1:
                    last_name_raw = name_parts[0]
                    first_name_raw = " ".join(name_parts[1:])
                    if self._contains_cyrillic(last_name_raw):
                        last_name_raw = self._transliterate(last_name_raw)
                    if self._contains_cyrillic(first_name_raw):
                        first_name_raw = self._transliterate(first_name_raw)
                    last_name_raw = self._normalize_token(last_name_raw)
                    first_name_raw = self._normalize_token(first_name_raw)
                    mrz_data["last_name"] = last_name_raw
                    mrz_data["first_name"] = first_name_raw

        if len(line2) >= 10:
            doc_field = line2[0:9]
            doc_check = line2[9]
            doc_number = doc_field.replace("<", "")
            if doc_number:
                if doc_check.isdigit() and self._calculate_mrz_check_digit(doc_field) == int(doc_check):
                    mrz_data["document_number"] = doc_number
                elif doc_number:
                    mrz_data["document_number"] = doc_number

        raw_exp = line2[21:27] if len(line2) >= 27 else ""
        exp_check = line2[27] if len(line2) >= 28 else ""
        exp_date = self._mrz_date_to_iso(raw_exp)
        if exp_date:
            if exp_check.isdigit() and self._calculate_mrz_check_digit(raw_exp) == int(exp_check):
                mrz_data["expiration_date"] = exp_date
            elif not exp_check:
                mrz_data["expiration_date"] = exp_date

        return mrz_data

    def _mrz_date_to_iso(self, raw: str) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã MRZ YYMMDD -> DD.MM.YYYY"""
        if not raw or not raw.isdigit() or len(raw) != 6:
            return ""
        yy = int(raw[0:2])
        mm = int(raw[2:4])
        dd = int(raw[4:6])
        year = 2000 + yy
        current_year = datetime.now().year
        if year < current_year - 20:
            year += 100
        try:
            datetime(year, mm, dd)
            return f"{dd:02d}.{mm:02d}.{year}"
        except ValueError:
            return ""

    def parse_text(self, text: str) -> PassportData:
        """–û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ –ø–∞—Å–ø–æ—Ä—Ç–∞"""
        data = PassportData()

        if self.debug:
            print("\n" + "="*60)
            print("üîç –ù–ê–ß–ê–õ–û –ü–ê–†–°–ò–ù–ì–ê")
            print("="*60)

        # 0. –¢–µ–ª–µ—Ñ–æ–Ω (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –ø–æ–ø–∞–ª –≤ —Å–∫–∞–Ω)
        phone_match = re.search(r'(?:\+7|8)\s?\(?\d{3}\)?\s?\d{3}[\s-]?\d{2}[\s-]?\d{2}', text)
        if phone_match:
            data.phone = phone_match.group(0)

        # 1. –ò–ò–ù (12 —Ü–∏—Ñ—Ä –ø–æ–¥—Ä—è–¥)
        iin_candidates = re.findall(r'\b(\d{12})\b', text)
        chosen_iin = ""
        for cand in iin_candidates:
            if self.validate_iin_checksum(cand):
                chosen_iin = cand
                break
        if not chosen_iin and iin_candidates:
            chosen_iin = iin_candidates[0]  # –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π, –µ—Å–ª–∏ —á–µ–∫-—Å—É–º–º–∞ –Ω–µ –ø—Ä–æ—à–ª–∞

        if chosen_iin:
            data.iin = chosen_iin
            if self.debug:
                print(f"‚úÖ –ò–ò–ù: {data.iin}")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª –∏ –¥–∞—Ç—É —Ä–æ–∂–¥–µ–Ω–∏—è –∏–∑ –ò–ò–ù
            data.gender = self.get_gender_from_iin(data.iin)
            iin_dob = self.extract_date_from_iin(data.iin)
            if iin_dob and not data.dob:
                data.dob = iin_dob
                if self.debug:
                    print(f"‚úÖ –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è –∏–∑ –ò–ò–ù: {data.dob}")

        # 2. –ü–û–õ (–µ—Å–ª–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∏–∑ –ò–ò–ù)
        if not data.gender:
            # –ò—â–µ–º –ø–æ–ª –≤ —Ç–µ–∫—Å—Ç–µ
            gender_patterns = [
                r'(?:–ñ–´–ù–´–°–´|Sex|Gender)[\s:]*([–ú–ñMF–º–∂mf])',
                r'Sex[\s/]*([MF])',
                r'Gender[\s:]*([MF])',
            ]

            for pattern in gender_patterns:
                gender_match = re.search(pattern, text, re.IGNORECASE)
                if gender_match:
                    g = gender_match.group(1).upper()
                    if g in ['M', '–ú']:
                        data.gender = "M"
                    elif g in ['F', '–ñ']:
                        data.gender = "F"
                    if data.gender:
                        if self.debug:
                            print(f"‚úÖ –ü–æ–ª (—Ç–µ–∫—Å—Ç): {data.gender}")
                        break

        # 3. –ù–û–ú–ï–† –î–û–ö–£–ú–ï–ù–¢–ê (N + 8 —Ü–∏—Ñ—Ä)
        doc_patterns = [
            r'(N\d{8})',  # N12345678
            r'‚Ññ[\s]*([N–ê-–Ø0-9]{8,9})',  # ‚Ññ N12345678
            r'–ü–ê–°–ü–û–†–¢[^\n]*?([A-Z0-9]{8,9})',  # –ü–æ—Å–ª–µ —Å–ª–æ–≤–∞ –ü–ê–°–ü–û–†–¢
        ]

        for pattern in doc_patterns:
            doc_match = re.search(pattern, text)
            if doc_match:
                data.document_number = doc_match.group(1).strip()
                if self.debug:
                    print(f"‚úÖ –ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞: {data.document_number}")
                break

        # 4. –§–ê–ú–ò–õ–ò–Ø –ò –ò–ú–Ø
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —á–µ—Ä–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        surname_patterns = [
            r'(?:–¢–ï–ü\s*/?\s*–ó“∞“¢–ê–¢–ú–ï|–¢–ï–ü|–¢–ï–ì–Ü|Surname)[\s:]*\n+([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–ÅA-Z\s]+)',
            r'(?:Last\s*Name)[\s:]*\n+([A-Z\s]+)',
        ]

        raw_last_name = ""
        for pattern in surname_patterns:
            surname_match = re.search(pattern, text, re.IGNORECASE)
            if surname_match:
                raw_last_name = surname_match.group(1).strip()
                # –ü–∞—Ä—Å–∏–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –∏ –≤—ã–±–∏—Ä–∞–µ–º –ª–∞—Ç–∏–Ω–∏—Ü—É –µ—Å–ª–∏ –µ—Å—Ç—å
                lines = raw_last_name.split('\n')
                best_line = None
                best_score = -1
                best_vowels = -1
                for line in lines:
                    clean = line.strip()
                    if not clean or not re.match(r'^[A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å\s]+$', clean):
                        continue
                    latin_count = sum(1 for c in clean if 'A' <= c.upper() <= 'Z')
                    cyr_count = sum(1 for c in clean if '–ê' <= c.upper() <= '–Ø' or c in "–Å”ò”®“Æ“∞“í“ö“¢“∫–Ü")
                    vowel_count = sum(1 for c in clean if c.upper() in "AEIOUY")
                    score = latin_count * 2 - cyr_count
                    if (
                        score > best_score
                        or (score == best_score and vowel_count > best_vowels)
                        or (score == best_score and vowel_count == best_vowels)
                    ):
                        best_score = score
                        best_vowels = vowel_count
                        best_line = clean

                if best_line:
                    normalized = self._normalize_token(best_line)
                    data.last_name = normalized or best_line
                    if self.debug:
                        print(f"‚úÖ –§–∞–º–∏–ª–∏—è: {data.last_name}")
                break

        # –ò–º—è
        name_patterns = [
            r'(?:–ê–¢–´|Given\s*names?|First\s*Names?)[\s:]*\n+([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å\s\n]+)',
            r'GIVEN\s*NAMES?[\s:]*\n+([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å\s\n]+)',
            r'–ê–¢–´[^\n]*\n+([A-Z–ê-–Ø”ò”®“Æ“∞“í“ö“¢“∫–Ü–Å\s\n]+)',
        ]

        for pattern in name_patterns:
            name_match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
            if name_match:
                name_text = name_match.group(1).strip()
                lines = [ln.strip() for ln in name_text.split('\n') if ln.strip()]
                if lines:
                    best_line = max(lines, key=lambda l: sum(1 for c in l if 'A' <= c.upper() <= 'Z'))
                    cleaned = self._normalize_token(best_line)
                    if cleaned and len(cleaned) > 2 and "PASSPORT" not in cleaned.upper():
                        parts = cleaned.split()
                        if len(parts) > 1 and len(parts[0]) <= 3 and len(parts[1]) > 3:
                            cleaned = parts[1]  # –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–π –ø—Ä–µ—Ñ–∏–∫—Å –≤—Ä–æ–¥–µ ZH
                        data.first_name = cleaned
                        if self.debug:
                            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∏–º—è: {data.first_name}")
                        break

        # –î–æ–ø. —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ –∏–º—è –≤—Å–µ –µ—â—ë –ø—É—Å—Ç–æ–µ, –±–µ—Ä–µ–º –ª–∞—Ç–∏–Ω–∏—Ü—É –∏–∑ —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å–ª–æ–≤
        if not data.first_name:
            lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
            latin_lines = []
            for ln in lines:
                cleaned = self._normalize_token(ln)
                if not cleaned or len(cleaned) < 2 or len(cleaned) > 30:
                    continue
                up = cleaned.upper()
                if any(x in up for x in ["PASSPORT", "KAZ", "NATIONALITY", "MINISTRY"]):
                    continue
                if up == (data.last_name or "").upper():
                    continue
                latin_lines.append(cleaned)
            if latin_lines:
                data.first_name = latin_lines[0]
                if self.debug:
                    print(f"‚úÖ –ò–º—è –ø–æ –ª–∞—Ç–∏–Ω–∏—Ü–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞: {data.first_name}")

        # –î–æ–ø. fallback –¥–ª—è —Ñ–∞–º–∏–ª–∏–∏: –∏—â–µ–º –ª—é–±—É—é –ø–æ–¥—Ö–æ–¥—è—â—É—é —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ –µ—â—ë –ø—É—Å—Ç–æ
        if not data.last_name:
            for ln in text.splitlines():
                cleaned = self._normalize_token(ln)
                if not cleaned or len(cleaned) < 4 or len(cleaned) > 25:
                    continue
                up = cleaned.upper()
                if any(x in up for x in ["PASSPORT", "KAZ", "NATIONALITY", "MINISTRY", "GIVEN", "SURNAME"]):
                    continue
                if data.first_name and up == data.first_name.upper():
                    continue
                parts = cleaned.split()
                if len(parts) > 1 and len(parts[-1]) <= 2:
                    cleaned = " ".join(parts[:-1])
                data.last_name = cleaned
                if self.debug:
                    print(f"‚úÖ –§–∞–º–∏–ª–∏—è (fallback): {data.last_name}")
                break

        # –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–æ–ø–∞–ª–∏ –ª–∏ –æ–±–∞ –∏–º–µ–Ω–∏ –≤ –æ–¥–Ω–æ –ø–æ–ª–µ
        if data.last_name and not data.first_name:
            # –ï—Å–ª–∏ –≤ —Ñ–∞–º–∏–ª–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤, –≤–æ–∑–º–æ–∂–Ω–æ —Ç–∞–º –∏ –∏–º—è —Ç–æ–∂–µ
            if len(data.last_name.split()) > 1:
                if self.debug:
                    print(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≤ —Ñ–∞–º–∏–ª–∏–∏: {data.last_name}")
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —É–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
                split_last, split_first = self._smart_name_split(data.last_name)
                if split_first:  # –ï—Å–ª–∏ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å
                    data.last_name = split_last
                    data.first_name = split_first
                    if self.debug:
                        print(f"‚úÖ –ü–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è - –§–∞–º–∏–ª–∏—è: {data.last_name}, –ò–º—è: {data.first_name}")

        elif data.first_name and not data.last_name:
            # –ï—Å–ª–∏ –∏–º—è –µ—Å—Ç—å, –∞ —Ñ–∞–º–∏–ª–∏–∏ –Ω–µ—Ç - –≤–æ–∑–º–æ–∂–Ω–æ –≤—Å–µ –≤ –∏–º–µ–Ω–∏
            if len(data.first_name.split()) > 1:
                if self.debug:
                    print(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≤ –∏–º–µ–Ω–∏: {data.first_name}")
                split_last, split_first = self._smart_name_split(data.first_name)
                data.last_name = split_last
                data.first_name = split_first
                if self.debug:
                    print(f"‚úÖ –ü–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è - –§–∞–º–∏–ª–∏—è: {data.last_name}, –ò–º—è: {data.first_name}")

        # 5. –î–ê–¢–´
        # –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è
        if not data.dob:
            dob_patterns = [
                r'(?:–¢–£“í–ê–ù\s*–ö“Æ–ù–Ü|Date\s*of\s*birth|–î–∞—Ç–∞\s*—Ä–æ–∂–¥–µ–Ω–∏—è)[\s:]*(\d{2}[./]\d{2}[./]\d{4})',
                r'(?:Born|–†–æ–¥–∏–ª—Å—è)[\s:]*(\d{2}[./]\d{2}[./]\d{4})',
                r'(\d{2}\.\d{2}\.\d{4})',  # –ü—Ä–æ—Å—Ç–æ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã
            ]

            for pattern in dob_patterns:
                dob_match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
                if dob_match:
                    data.dob = dob_match.group(1).replace('/', '.')
                    if self.debug:
                        print(f"‚úÖ –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è: {data.dob}")
                    break

        # –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è
        exp_patterns = [
            r'(?:–ú–ï–†–ó–Ü–ú(?:–Ü)?|–ñ–ê–†–ê–ú–î–´\s*–î–û|Expiry|Expires|Valid\s*(?:until|to)|Date\s*of\s*Expiry|–î–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω\s*–¥–æ)[^\d]*(\d{2}\s*[./-]\s*\d{2}\s*[./-]\s*\d{4})',
            r'(?:Valid\s*until)[\s:]*(\d{2}\s*[./-]\s*\d{2}\s*[./-]\s*\d{4})',
            r'(?:–¥–æ\s*)(\d{2}\s*[./-]\s*\d{2}\s*[./-]\s*\d{4})',
        ]

        for pattern in exp_patterns:
            exp_match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if exp_match:
                data.expiration_date = self._clean_date(exp_match.group(1))
                if self.debug:
                    print(f"‚úÖ –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è: {data.expiration_date}")
                break

        # 6. MRZ OVERRIDE (—Å–∞–º—ã–π —Ç–æ—á–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–º–µ–Ω –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏)
        mrz_data = self.parse_mrz(text)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º MRZ –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π (—Ç–µ–ø–µ—Ä—å —Ç–∞–º –≤—Å–µ–≥–¥–∞ –ª–∞—Ç–∏–Ω–∏—Ü–∞ –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏)
        use_mrz = False
        if mrz_data.get("last_name"):
            mrz_last = mrz_data["last_name"]
            mrz_first = mrz_data.get("first_name", "")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Å–ª–æ–≤–∞—Ä—è (—á—Ç–æ–±—ã —Ñ—Ä–æ–Ω—Ç –±—Ä–∞–ª –ª–∞—Ç–∏–Ω–∏—Ü—É)
            self.mrz_last_name = mrz_last
            self.mrz_first_name = mrz_first

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ MRZ: –µ—Å—Ç—å –ª–∏ –≤ –Ω–µ–º —Ö–æ—Ç—è –±—ã 2 –±—É–∫–≤—ã
            if len(mrz_last) >= 2 and mrz_last.replace(" ", "").isalpha():
                use_mrz = True

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–æ–ø–∞–ª–∏ –ª–∏ –æ–±–∞ –∏–º–µ–Ω–∏ –≤ –æ–¥–Ω–æ –ø–æ–ª–µ
                if mrz_last and not mrz_first and len(mrz_last.split()) > 1:
                    if self.debug:
                        print(f"‚ö†Ô∏è MRZ: –ù–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≤ —Ñ–∞–º–∏–ª–∏–∏: {mrz_last}")
                    split_last, split_first = self._smart_name_split(mrz_last)
                    data.last_name = split_last
                    data.first_name = split_first
                    if self.debug:
                        print(f"‚úÖ MRZ –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è - –§–∞–º–∏–ª–∏—è: {data.last_name}, –ò–º—è: {data.first_name}")
                else:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º MRZ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è —Ö—É–∂–µ –∏–ª–∏ –ø—É—Å—Ç—ã
                    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –ª–∞—Ç–∏–Ω–∏—Ü–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ > MRZ > –∫–∏—Ä–∏–ª–ª–∏—Ü–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
                    text_last_has_latin = data.last_name and not self._contains_cyrillic(data.last_name)
                    text_first_has_latin = data.first_name and not self._contains_cyrillic(data.first_name)

                    if not text_last_has_latin or not data.last_name:
                        data.last_name = mrz_last
                        if self.debug:
                            print(f"‚úÖ –§–∞–º–∏–ª–∏—è (MRZ): {data.last_name}")

                    if mrz_first and (not text_first_has_latin or not data.first_name):
                        data.first_name = mrz_first
                        if self.debug:
                            print(f"‚úÖ –ò–º—è (MRZ): {data.first_name}")
            else:
                if self.debug:
                    print(f"‚ö†Ô∏è MRZ —Ñ–∞–º–∏–ª–∏—è –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è: '{mrz_last}'")

        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è –≤—Å—ë –µ—â—ë –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ ‚Äî —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º
        if self._contains_cyrillic(data.last_name):
            old_last = data.last_name
            data.last_name = self._transliterate(data.last_name)
            if self.debug:
                print(f"üîÑ –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è —Ñ–∞–º–∏–ª–∏–∏: {old_last} ‚Üí {data.last_name}")

        if self._contains_cyrillic(data.first_name):
            old_first = data.first_name
            data.first_name = self._transliterate(data.first_name)
            if self.debug:
                print(f"üîÑ –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏: {old_first} ‚Üí {data.first_name}")

        if mrz_data.get("document_number") and not data.document_number:
            data.document_number = mrz_data["document_number"]
            if self.debug:
                print(f"‚úÖ –ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ (MRZ): {data.document_number}")
        if mrz_data.get("expiration_date") and not data.expiration_date:
            data.expiration_date = mrz_data["expiration_date"]
            if self.debug:
                print(f"‚úÖ –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è (MRZ): {data.expiration_date}")

        if not data.expiration_date:
            generic_matches = re.findall(r'(\d{2}(?:\s*[./-]\s*|\s+)\d{2}(?:\s*[./-]\s*|\s+)\d{4})', text)
            for match in reversed(generic_matches):
                cleaned = self._clean_date(match)
                if cleaned and cleaned != data.dob:
                    data.expiration_date = cleaned
                    if self.debug:
                        print(f"‚úÖ –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è (fallback): {data.expiration_date}")
                    break

        if self.debug:
            print("="*60)
            print(f"üìä –ò–¢–û–ì–û–í–´–ï –î–ê–ù–ù–´–ï:")
            print(f"   –§–∞–º–∏–ª–∏—è: {data.last_name}")
            print(f"   –ò–º—è: {data.first_name}")
            print(f"   –ü–æ–ª: {data.gender}")
            print(f"   –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è: {data.dob}")
            print(f"   –ò–ò–ù: {data.iin}")
            print(f"   –î–æ–∫—É–º–µ–Ω—Ç: {data.document_number}")
            print(f"   –°—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è: {data.expiration_date}")
            print(f"   –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å: {data.is_valid}")
            print("="*60 + "\n")

        return data

    def parse(self, file_path: str) -> PassportData:
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ñ–∞–π–ª–∞"""
        text = self.extract_ocr_text(file_path)
        return self.parse_text(text)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
def test_parser(file_path: str):
    parser = PassportParser(debug=True)
    result = parser.parse(file_path)
    print("\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢:")
    print(result.to_dict())
    return result
